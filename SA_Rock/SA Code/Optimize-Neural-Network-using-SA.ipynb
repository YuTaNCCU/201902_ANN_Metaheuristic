{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: Load Dataset\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#資料集是以dictionary的形式存在\n",
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.4 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "df_feat.info()\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_feat.iloc[:, ].values\n",
    "y = cancer['target']\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND = tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD,adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\howard\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\howard\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "c:\\users\\howard\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "c:\\users\\howard\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\howard\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu', input_dim=30))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 846us/step - loss: 0.6931 - acc: 0.4901\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6916 - acc: 0.6374\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6897 - acc: 0.6484\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6869 - acc: 0.6791\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6825 - acc: 0.7473\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6761 - acc: 0.8242\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6661 - acc: 0.8945\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6522 - acc: 0.9209\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.6332 - acc: 0.9297\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.6069 - acc: 0.9363\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.5750 - acc: 0.9429\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.5369 - acc: 0.9429\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.4925 - acc: 0.9495\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.4470 - acc: 0.9516\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.3988 - acc: 0.9560\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.3515 - acc: 0.9560\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.3020 - acc: 0.9604\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.2661 - acc: 0.9626\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.2344 - acc: 0.9648\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.2069 - acc: 0.9692\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.1840 - acc: 0.9736\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1685 - acc: 0.9714\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1484 - acc: 0.9736\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.1438 - acc: 0.9736\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1295 - acc: 0.9736\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.1222 - acc: 0.9736\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1115 - acc: 0.9736\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.1047 - acc: 0.9736\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.1000 - acc: 0.9758\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0984 - acc: 0.9758\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0936 - acc: 0.9824\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0939 - acc: 0.9780\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0884 - acc: 0.9780\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0853 - acc: 0.9780\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0878 - acc: 0.9802\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0814 - acc: 0.9846\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0831 - acc: 0.9846\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0779 - acc: 0.9824\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0745 - acc: 0.9824\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0772 - acc: 0.9780\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0768 - acc: 0.9824\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 39us/step - loss: 0.0766 - acc: 0.9846\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0690 - acc: 0.9868\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0692 - acc: 0.9890\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0645 - acc: 0.9824\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 39us/step - loss: 0.0676 - acc: 0.9890\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0661 - acc: 0.9868\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0628 - acc: 0.9868\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0672 - acc: 0.9868\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 28us/step - loss: 0.0682 - acc: 0.9846\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0640 - acc: 0.9846\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0625 - acc: 0.9868\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0589 - acc: 0.9868\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0630 - acc: 0.9868\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0654 - acc: 0.9868\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 28us/step - loss: 0.0588 - acc: 0.9868\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0579 - acc: 0.9912\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0571 - acc: 0.9890\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0572 - acc: 0.9890\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0549 - acc: 0.9890\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0616 - acc: 0.9868\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0605 - acc: 0.9890\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0589 - acc: 0.9890\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0565 - acc: 0.9890\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0579 - acc: 0.9890\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0549 - acc: 0.9890\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0593 - acc: 0.9868\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0557 - acc: 0.9912\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0571 - acc: 0.9890\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0532 - acc: 0.9890\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0541 - acc: 0.9890\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0514 - acc: 0.9912\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0530 - acc: 0.9890\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0561 - acc: 0.9890\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0541 - acc: 0.9868\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 35us/step - loss: 0.0517 - acc: 0.9890\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0549 - acc: 0.9890\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0538 - acc: 0.9890\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0500 - acc: 0.9890\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0489 - acc: 0.9890\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0544 - acc: 0.9868\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0494 - acc: 0.9912\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0513 - acc: 0.9912\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 33us/step - loss: 0.0496 - acc: 0.9890\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0487 - acc: 0.9912\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0484 - acc: 0.9890\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0496 - acc: 0.9890\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0437 - acc: 0.9890\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0472 - acc: 0.9890\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0514 - acc: 0.9912\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0484 - acc: 0.9890\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0423 - acc: 0.9912\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0450 - acc: 0.9890\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0462 - acc: 0.9890\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0491 - acc: 0.9890\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0474 - acc: 0.9912\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0479 - acc: 0.9890\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 31us/step - loss: 0.0476 - acc: 0.9890\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0482 - acc: 0.9890\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0476 - acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19a92277f28>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Results(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 94.73684210526315%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_original = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Our accuracy is {}%\".format(((cm_original[0][0] + cm_original[1][1])/114)*100))\n",
    "\n",
    "sns.heatmap(cm_original,annot=True)\n",
    "plt.savefig('original.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = classifier.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlattenWeights(weights):\n",
    "        \"\"\"\n",
    "        flatten weights\n",
    "        \n",
    "        param weights: keras神經網路的權重格式:nparray包在list中\n",
    "        return WeightsStrucure : 神經網路各層的權重shape包在list中，unflatten時會用到\n",
    "        return FlattenedWeights : 一維list包含所有的權重\n",
    "        \"\"\"\n",
    "        WeightsStrucure = []\n",
    "        FlattenedWeights = []\n",
    "        for i_layer in weights:\n",
    "            WeightsStrucure.append(i_layer.shape)\n",
    "            if len(i_layer.shape) == 1 :# 該層權重的shape為一維 e.g. (15,)      \n",
    "                FlattenedWeights.extend(i_layer)\n",
    "            else :# 該層權重的shape為二維 e.g. (30, 15)  \n",
    "                for i_links in i_layer:\n",
    "                    FlattenedWeights.extend(i_links)\n",
    "        return WeightsStrucure, FlattenedWeights\n",
    "\n",
    "def UnflattenWeights(WeightsStrucure, ModifiedWeights):\n",
    "    \"\"\"\n",
    "    Unflatten(回復成原本的結構) weights  \n",
    "\n",
    "    param WeightsStrucure : 神經網路各層的權重shape包在list中\n",
    "    param ModifiedWeights : 一維list包含所有meteHeuristic修改過的權重\n",
    "    return: keras神經網路的權重格式:nparray包在list中\n",
    "    \"\"\"\n",
    "    UnflattenWeights = []\n",
    "    i_index = 0 \n",
    "    for i_layer in WeightsStrucure:\n",
    "        if len(i_layer) == 1 : # 該層權重的shape為一維 e.g. (15,)      \n",
    "            TempList = ModifiedWeights[i_index:(i_index + i_layer[0])]\n",
    "            TempList = np.asarray(TempList)\n",
    "            i_index = i_index + i_layer[0]\n",
    "        else : # 該層權重的shape為二維 e.g. (30, 15)  \n",
    "            TempList = ModifiedWeights[i_index:(i_index + (i_layer[0]*i_layer[1]))]\n",
    "            TempList = np.reshape(TempList, i_layer )\n",
    "            i_index = i_index + (i_layer[0]*i_layer[1])\n",
    "        UnflattenWeights.append(TempList)\n",
    "    return UnflattenWeights    \n",
    "\n",
    "def score(X_train= X_train,y_train = y_train ,Model = None):\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    mis_classification = 1 - ((cm[0][0] + cm[1][1])/114)\n",
    "    return mis_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model = classifier # 保存舊模型\n",
    "structure, weights =FlattenWeights(init_weights) # 拉平初始權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimize_SA(model = None , score = None , initT = 1000, minT = 1 , iterL = 5000 , delta = 0.95, k = 1, init_weights = None, structure = None):\n",
    "    old_score = score(model)\n",
    "    nowt = initT \n",
    "    # start SA!\n",
    "    while nowt > minT:\n",
    "        for i in range(iterL):\n",
    "            # 初始舊權重計算分數\n",
    "            # 製作新的權重\n",
    "            xnew = init_weights + (np.random.rand(len(init_weights)) - 0.5)\n",
    "            process_weights = UnflattenWeights(structure, xnew )\n",
    "            model.set_weights(process_weights)\n",
    "            new_score = score(model)\n",
    "            # 計算分數差異\n",
    "            res = new_score - old_score\n",
    "            if res < 0:\n",
    "                init_weights = xnew\n",
    "                old_score = new_score\n",
    "            else:\n",
    "                p = np.exp(-res / (k * nowt))\n",
    "                if np.random.rand() < p:\n",
    "                    init_weights = xnew\n",
    "                    old_score = new_score\n",
    "                else:\n",
    "                    pass\n",
    "            nowt = nowt * delta\n",
    "    return model\n",
    "\n",
    "SA_Model = Optimize_SA(model = classifier, score = score, init_weights= weights, structure= structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_Model = Optimize_SA(model = classifier, score = score, init_weights= weights, structure= structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Results(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = SA_Model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/114)*100))\n",
    "\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
