{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JlwH6ajIzAuM"
   },
   "source": [
    "# Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "du8JiNhSoMMQ"
   },
   "outputs": [],
   "source": [
    "#待續\n",
    "# 紅白酒資料>Ｙ分成01>split>score（recall, precision, AUC）\n",
    "# 親代個數先設定權重數目的2倍\n",
    "# 若無改善，試試看multi phase ES 迭代結果子代的10%再從頭開始\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rhYgessUEZb"
   },
   "outputs": [],
   "source": [
    "#https://github.com/YuTaNCCU/201902_ANN_Metaheuristic/tree/master/ES\n",
    "import random\n",
    "import pandas as pd\n",
    "from string import ascii_lowercase\n",
    "from copy import deepcopy\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from copy import deepcopy\n",
    "from collections import deque\n",
    "from numpy import argmax\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import  seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UR8bAYdozEEv"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNbHjxYPh0i5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4898, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6497, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>WineCatg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality WineCatg  \n",
       "0      9.4        5      red  \n",
       "1      9.8        5      red  \n",
       "2      9.8        5      red  \n",
       "3      9.8        6      red  \n",
       "4      9.4        5      red  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>WineCatg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality WineCatg  \n",
       "4893     11.2        6    white  \n",
       "4894      9.6        5    white  \n",
       "4895      9.4        6    white  \n",
       "4896     12.8        7    white  \n",
       "4897     11.8        6    white  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/YuTaNCCU/201902_ANN_Metaheuristic/master/Data/red.csv'\n",
    "red = pd.read_csv(url)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/YuTaNCCU/201902_ANN_Metaheuristic/master/Data/white.csv'\n",
    "white = pd.read_csv(url)\n",
    "\n",
    "red['WineCatg']='red'\n",
    "white['WineCatg']='white'\n",
    "Wine_Data = pd.concat([red, white])\n",
    "\n",
    "display(\n",
    "    red.shape,\n",
    "  white.shape,\n",
    "  Wine_Data.shape,\n",
    "  Wine_Data.head(5),\n",
    "  Wine_Data.tail(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原本各種quality記數: \n",
      " 3      30\n",
      "4     216\n",
      "5    2138\n",
      "6    2836\n",
      "7    1079\n",
      "8     193\n",
      "9       5\n",
      "Name: quality, dtype: int64\n",
      "分類成好壞兩種quality記數: \n",
      " 0    2384\n",
      "1    4113\n",
      "Name: quality, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>WineCatg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality WineCatg  \n",
       "0      9.4        0      red  \n",
       "1      9.8        0      red  \n",
       "2      9.8        0      red  \n",
       "3      9.8        1      red  \n",
       "4      9.4        0      red  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( '原本各種quality記數: \\n', Wine_Data.quality.value_counts().sort_index() )\n",
    "Wine_Data_Y01 = Wine_Data.replace({'quality':[3,4,5,6,7,8,9]},{'quality':[0,0,0,1,1,1,1]})\n",
    "print( '分類成好壞兩種quality記數: \\n', Wine_Data_Y01.quality.value_counts().sort_index() )\n",
    "Wine_Data_Y01.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4157, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1040, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1300, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4157,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1300,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=Wine_Data_Y01.drop(['quality', 'WineCatg'], axis=1)\n",
    "y=Wine_Data_Y01['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state= 123)\n",
    "\n",
    "display(\n",
    "      X_train.shape,\n",
    "      X_val.shape,\n",
    "      X_test.shape,\n",
    "      y_train.shape,\n",
    "      y_val.shape,\n",
    "      y_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isg-ogGRUHat"
   },
   "source": [
    "# Define ES class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "Eu47m1CnUrM1"
   },
   "outputs": [],
   "source": [
    "class ES:\n",
    "    \"\"\"\n",
    "    Conducts tabu search\n",
    "    \"\"\"\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    #default hyper parameters\n",
    "    InitialSigma = None\n",
    "    ParentsSize = None\n",
    "    ChildSize = None\n",
    "    tao = None\n",
    "    \n",
    "    #for input/output\n",
    "    KerasModels = None\n",
    "    WeightsStrucure = None   \n",
    "    weights = None\n",
    "    \n",
    "    #for record\n",
    "    cur_steps = 1\n",
    "    best_weight = None\n",
    "    best_score = None\n",
    "    \n",
    "    UseOLSReg=None\n",
    "    X_train=None\n",
    "    y_train=None\n",
    "    \n",
    "    def __init__(self, KerasModels, X_train, y_train, UseOLSReg=False, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5):\n",
    "        \"\"\"\n",
    "        :param KerasModels: a Keras model, like keras.engine.sequential.Sequential\n",
    "        :param weights: initial weights, should be a Keras model weight\n",
    "        :param max_steps: maximum number of steps to run algorithm for\n",
    "        :param UseOLSReg: If True, than use \"OLS Regression\" for the last layer\n",
    "        \n",
    "        \"\"\"\n",
    "        self.KerasModels = KerasModels\n",
    "        \n",
    "        self.UseOLSReg = UseOLSReg\n",
    "        \n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    " \n",
    "        if all(isinstance(x, float) for x in [InitialSigma, tao]) and all(x > 0 for x in [InitialSigma, tao]):\n",
    "            self.InitialSigma = InitialSigma\n",
    "            self.tao = tao\n",
    "        else:\n",
    "            raise TypeError('InitialSigma & tao must be a positive float')\n",
    "            \n",
    "        if all(isinstance(x, int) for x in [ParentsSize, ChildSize]) and all(x > 0 for x in [ParentsSize, ChildSize]):\n",
    "            self.ParentsSize = ParentsSize\n",
    "            self.ChildSize = ChildSize\n",
    "        else:\n",
    "            raise TypeError('ParentsSize, ChildSize & max_steps must be a positive integer')\n",
    "\n",
    "    def __str__(self): \n",
    "        return ('ES STEPS: %d ' +\n",
    "                'BEST SCORE: %.4f ') % \\\n",
    "               (self.cur_steps, self.best_score)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__() \n",
    "    \n",
    "    def _FlattenWeights(self, weights):\n",
    "        \"\"\"\n",
    "        flatten weights\n",
    "        \n",
    "        param weights: keras神經網路的權重格式:nparray包在list中\n",
    "        return WeightsStrucure : 神經網路各層的權重shape包在list中，unflatten時會用到\n",
    "        return FlattenedWeights : 一維list包含所有的權重\n",
    "        \"\"\"\n",
    "        WeightsStrucure = []\n",
    "        FlattenedWeights = []\n",
    "        for i_layer in weights:\n",
    "            WeightsStrucure.append(i_layer.shape)\n",
    "            if len(i_layer.shape) == 1 :# 該層權重的shape為一維 e.g. (15,)      \n",
    "                FlattenedWeights.extend(i_layer)\n",
    "            else :# 該層權重的shape為二維 e.g. (30, 15)  \n",
    "                for i_links in i_layer:\n",
    "                    FlattenedWeights.extend(i_links)\n",
    "        return WeightsStrucure, FlattenedWeights\n",
    "\n",
    "    def _UnflattenWeights(self, WeightsStrucure, ModifiedWeights):\n",
    "        \"\"\"\n",
    "        Unflatten(回復成原本的結構) weights  \n",
    "        \n",
    "        param WeightsStrucure : 神經網路各層的權重shape包在list中\n",
    "        param ModifiedWeights : 一維list包含所有meteHeuristic修改過的權重\n",
    "        return: keras神經網路的權重格式:nparray包在list中\n",
    "        \"\"\"\n",
    "        UnflattenWeights = []\n",
    "        i_index = 0 \n",
    "        for i_layer in WeightsStrucure:\n",
    "            if len(i_layer) == 1 : # 該層權重的shape為一維 e.g. (15,)      \n",
    "                TempList = ModifiedWeights[i_index:(i_index + i_layer[0])]\n",
    "                TempList = np.asarray(TempList)\n",
    "                i_index = i_index + i_layer[0]\n",
    "            else : # 該層權重的shape為二維 e.g. (30, 15)  \n",
    "                TempList = ModifiedWeights[i_index:(i_index + (i_layer[0]*i_layer[1]))]\n",
    "                TempList = np.reshape(TempList, i_layer )\n",
    "                i_index = i_index + (i_layer[0]*i_layer[1])\n",
    "            UnflattenWeights.append(TempList)\n",
    "        return UnflattenWeights   \n",
    "    \n",
    "    def _best(self, Population_Child_score):\n",
    "        \"\"\"\n",
    "        Finds the best member of a neighborhood\n",
    "        :param Population_Child_score: a np array\n",
    "        :return: the indtex of N best member, N = ParentsSize\n",
    "        \"\"\"\n",
    "        return np.array( Population_Child_score ).argsort()[::-1][:self.ParentsSize]\n",
    "    \n",
    "    def _Recombination(self, Population_Parents_Weights, Population_Parents_Sigma, rows): #GenerateParents\n",
    "        \"\"\"\n",
    "        Generate New Parents Polulation\n",
    "        \"\"\"\n",
    "        Population_Weights_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
    "        Population_Sigma_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
    "        for index_row, _ in enumerate( Population_Weights_Recombination ):\n",
    "            \"\"\"\n",
    "            可能可以平行計算\n",
    "            \"\"\"\n",
    "            TwoRowschoiced = np.random.choice(Population_Parents_Weights.shape[0], size=2, replace=False,)\n",
    "            Parent1Mask = np.random.randint(2, size=Population_Parents_Weights.shape[1])\n",
    "            Parent2Mask = np.full(shape = Population_Parents_Weights.shape[1], fill_value = 1 )  - Parent1Mask\n",
    "            \n",
    "            Population_Weights_Recombination[index_row,:] = (Population_Parents_Weights[TwoRowschoiced] * [Parent1Mask, Parent2Mask]).sum(axis=0)\n",
    "            Population_Sigma_Recombination[index_row,:] = Population_Parents_Sigma[TwoRowschoiced].mean(axis=0)\n",
    "        return Population_Weights_Recombination, Population_Sigma_Recombination\n",
    "\n",
    "    def _score(self, ModifiedWeights):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns objective function value of a state\n",
    "\n",
    "        :param state: a state\n",
    "        :return: objective function value of state\n",
    "        \"\"\"\n",
    "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
    "        self.KerasModels.set_weights(UnflattenedWeights)\n",
    "        test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
    "        return test_on_batch[1]\n",
    "    #==================\n",
    "        #==================\n",
    "          #==================\n",
    "            #==================\n",
    "    def _OLSReg(self, ModifiedWeights):\n",
    "        \n",
    "        \"\"\"\n",
    "        :param : \n",
    "        :return: Keras Models, objective function value of state\n",
    "        \"\"\"\n",
    "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
    "        \n",
    "        #%% OLS Regression\n",
    "        #obtain the output of an intermediate layer\n",
    "        #https://keras.io/getting-started/faq/?fbclid=IwAR3Zv35V-vmEy85anudOrlxCExXYwyG6cRL1UR0AaLPU6sZEoBjsbX-8LXQ#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "        self.KerasModels.set_weights(UnflattenedWeights)\n",
    "        layer_name = 'IntermediateLayer'\n",
    "        intermediate_layer_model = keras_models_Model(inputs=self.KerasModels.input,\n",
    "                                         outputs=self.KerasModels.get_layer(layer_name).output)\n",
    "        intermediate_output = intermediate_layer_model.predict(self.X_train)\n",
    "\n",
    "        #fit LM\n",
    "        lm =  LogisticRegression(random_state=0, solver='liblinear').fit(intermediate_output, self.y_train)\n",
    "        \n",
    "        #lm =  LinearRegression().fit(intermediate_output, self.y_train)\n",
    "        # 印出係數, 截距 print(lm.coef_, lm.intercept_)\n",
    "        \n",
    "        #score\n",
    "        #score = log_loss(y_pred = lm.predict(intermediate_output), y_true= self.y_train)\n",
    "        \n",
    "        #get OutLayerWeights\n",
    "        OutLayerWeights = [np.array(lm.coef_).reshape(self.WeightsStrucure[-2]),\n",
    "                           np.array(lm.intercept_).reshape(self.WeightsStrucure[-1])]\n",
    "\n",
    "        #update ES-optimized weights\n",
    "        UnflattenedWeights[-2:] = OutLayerWeights        \n",
    "        \n",
    "        #self.KerasModels.set_weights(UnflattenedWeights)\n",
    "        #test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
    "        \n",
    "        #print( 'score',score, 'test_on_batch',test_on_batch)\n",
    "        _, OLS_Optimized_Weight = self._FlattenWeights(UnflattenedWeights)\n",
    "        return OLS_Optimized_Weight \n",
    "\n",
    "    def run(self, weights, max_steps=5, verbose=10, useOLSReg = False):\n",
    "        \"\"\"\n",
    "        Conducts ES\n",
    "        :param weights: \n",
    "        :param max_steps: \n",
    "        :param verbose: int which indicates how many iter to show score\n",
    "        :return: Keras Models, best state and objective function value of best state\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(weights, list)  :\n",
    "          \n",
    "            self.WeightsStrucure, self.weights = self._FlattenWeights(weights)\n",
    "            self.best_weight = self.weights\n",
    "            self.best_score = self._score(self.best_weight)\n",
    "        else:\n",
    "            raise TypeError('initial_state must be a list') \n",
    "            \n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "        #Step1 initial             \n",
    "        Population_Parents_Weights = np.array([self.weights, self.weights])         \n",
    "        Population_Parents_Sigma = np.full(shape = (self.ParentsSize, len(self.weights)), fill_value = self.InitialSigma ) \n",
    "        Population_Parents_Weights, _ = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ParentsSize )\n",
    "        self.cur_steps = 1\n",
    "        while True:   \n",
    "            #Step2 Child\n",
    "            ##Discrete Recombination\n",
    "            Population_Child_Weights, Population_Child_Sigma = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ChildSize )\n",
    "            ##mutation1\n",
    "            RamdonNormalValue = np.random.normal(0, 1, 1)\n",
    "            RamdonNormalValueDifferent = np.random.normal(0, 1, Population_Child_Sigma.shape)\n",
    "            Population_Child_Sigma = np.exp( (1-self.tao)*RamdonNormalValue + self.tao*RamdonNormalValueDifferent )\n",
    "            ##mutation2\n",
    "            Population_Child_Weights = Population_Child_Weights + np.random.normal(0, Population_Child_Sigma, Population_Child_Sigma.shape)\n",
    "            \n",
    "            \n",
    "            # OLS Regression\n",
    "            if useOLSReg == True:\n",
    "              for i, i_Child in enumerate(Population_Child_Weights) :\n",
    "                  OLS_Optimized_Weight = self._OLSReg(i_Child)\n",
    "                  #print(OLS_Optimized_Weight,'i:\\n', i, Population_Child_Weights[i])\n",
    "                  Population_Child_Weights[i] = OLS_Optimized_Weight\n",
    "            \n",
    "            \n",
    "            #step3 Evaluation\n",
    "            Population_Child_score = []\n",
    "            for i_Child in Population_Child_Weights :\n",
    "                \"\"\"\n",
    "                可能可以平行計算\n",
    "                \"\"\"\n",
    "                Population_Child_score.append( self._score(i_Child) )\n",
    "                 \n",
    "            BestNIndex = self._best(Population_Child_score)\n",
    "            Population_Parents_Weights = Population_Child_Weights[BestNIndex,:]\n",
    "            Population_Parents_Sigma = Population_Child_Sigma[BestNIndex,:]\n",
    "            \n",
    "            #更新best\n",
    "            best_weight_This_Iter =  Population_Child_Weights[BestNIndex,:][0]\n",
    "            best_score_This_Iter = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
    "            if best_score_This_Iter > self.best_score:\n",
    "                self.best_weight =  Population_Child_Weights[BestNIndex,:][0]\n",
    "                self.best_score = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
    "        \n",
    "            #print process \n",
    "            if ((self.cur_steps ) % verbose == 0) and verbose:\n",
    "               print(self)\n",
    "                \n",
    "            self.cur_steps = self.cur_steps + 1\n",
    "            #step4 check stop criteria\n",
    "            if self.cur_steps > max_steps:\n",
    "                print( 'Stop: Reach max_steps' )\n",
    "                break\n",
    "        return self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = self.best_weight), self.best_score \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgjIusZlzDaT"
   },
   "source": [
    "# Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "IBrIxe5CU5Nz",
    "outputId": "14928888-e0d9-4fd6-ec41-68f80f096506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "IntermediateLayer (Dense)    (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, Model as keras_models_Model\n",
    "\n",
    "K.clear_session() \n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(round(X_train.shape[1]/2), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "#model.add(Dense(round(X_train.shape[1]/2), activation='relu'))\n",
    "model.add(Dense(round(X_train.shape[1]/4), activation='relu', name = 'IntermediateLayer'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULIddEh0zWGU"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1884
    },
    "colab_type": "code",
    "id": "zE_V_96FU9yy",
    "outputId": "13503c1e-ff7a-4064-f97e-359f6a60818a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES STEPS: 1 BEST SCORE: 0.6618 \n",
      "ES STEPS: 2 BEST SCORE: 0.6690 \n",
      "ES STEPS: 3 BEST SCORE: 0.6690 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2878 - acc: 0.6688\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.3581 - acc: 0.6647\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 73us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 72us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2747 - acc: 0.6700\n",
      "ES STEPS: 1 BEST SCORE: 0.6724 \n",
      "ES STEPS: 2 BEST SCORE: 0.6738 \n",
      "ES STEPS: 3 BEST SCORE: 0.6738 \n",
      "ES STEPS: 4 BEST SCORE: 0.6738 \n",
      "ES STEPS: 5 BEST SCORE: 0.6738 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1983 - acc: 0.6745\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "ES STEPS: 1 BEST SCORE: 0.6738 \n",
      "ES STEPS: 2 BEST SCORE: 0.6738 \n",
      "ES STEPS: 3 BEST SCORE: 0.6738 \n",
      "ES STEPS: 4 BEST SCORE: 0.6738 \n",
      "ES STEPS: 5 BEST SCORE: 0.6777 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1914 - acc: 0.6748\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.4210 - acc: 0.6611\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.4106 - acc: 0.6615\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.3089 - acc: 0.6678\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.6989 - acc: 0.6442\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.6600 - acc: 0.6464\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.6418 - acc: 0.6478\n",
      "ES STEPS: 1 BEST SCORE: 0.6781 \n",
      "ES STEPS: 2 BEST SCORE: 0.6781 \n",
      "ES STEPS: 3 BEST SCORE: 0.6781 \n",
      "ES STEPS: 4 BEST SCORE: 0.6781 \n",
      "ES STEPS: 5 BEST SCORE: 0.6781 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2019 - acc: 0.6743\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1844 - acc: 0.6752\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2344 - acc: 0.6726\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 71us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 71us/step - loss: 5.2674 - acc: 0.6707\n",
      "ES STEPS: 1 BEST SCORE: 0.6791 \n",
      "ES STEPS: 2 BEST SCORE: 0.6801 \n",
      "ES STEPS: 3 BEST SCORE: 0.6813 \n",
      "ES STEPS: 4 BEST SCORE: 0.6813 \n",
      "ES STEPS: 5 BEST SCORE: 0.6813 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0921 - acc: 0.6813\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0992 - acc: 0.6803\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1266 - acc: 0.6791\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1383 - acc: 0.6781\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1404 - acc: 0.6779\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1251 - acc: 0.6791\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1270 - acc: 0.6784\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1206 - acc: 0.6789\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1373 - acc: 0.6781\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1917 - acc: 0.6748\n",
      "ES STEPS: 1 BEST SCORE: 0.6786 \n",
      "ES STEPS: 2 BEST SCORE: 0.6786 \n",
      "ES STEPS: 3 BEST SCORE: 0.6786 \n",
      "ES STEPS: 4 BEST SCORE: 0.6786 \n",
      "ES STEPS: 5 BEST SCORE: 0.6786 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.1252 - acc: 0.6791\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1190 - acc: 0.6793\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2067 - acc: 0.6740\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2294 - acc: 0.6724\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1775 - acc: 0.6760\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2767 - acc: 0.6700\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2768 - acc: 0.6700\n",
      "ES STEPS: 1 BEST SCORE: 0.6798 \n",
      "ES STEPS: 2 BEST SCORE: 0.6798 \n",
      "ES STEPS: 3 BEST SCORE: 0.6798 \n",
      "ES STEPS: 4 BEST SCORE: 0.6798 \n",
      "ES STEPS: 5 BEST SCORE: 0.6798 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 70us/step - loss: 5.1559 - acc: 0.6769\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.1873 - acc: 0.6748\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1161 - acc: 0.6796\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.1412 - acc: 0.6779\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 70us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.1759 - acc: 0.6757\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 71us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 73us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "weights = model.get_weights() \n",
    "MyES = ES(model, X_train, y_train, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5)   \n",
    "weights, ES_Optimized_ObjVal  = MyES.run(weights, useOLSReg =False, max_steps=3, verbose = 1)\n",
    "\n",
    "# Optimize\n",
    "GlobalBestAccuracy = 0\n",
    "NoImproveTimes = 0\n",
    "while True:\n",
    "  # Gradient-based Optimize\n",
    "  model.set_weights(weights)\n",
    "  model.fit(X_train, y_train, epochs=15, batch_size=32, verbose=1)\n",
    "  weights = model.get_weights() \n",
    "\n",
    "  # ES\n",
    "  weights, ES_Optimized_ObjVal  = MyES.run(weights, max_steps=5, verbose = 1)\n",
    "  \n",
    "  # Stop Criteria\n",
    "  if ES_Optimized_ObjVal > GlobalBestAccuracy:\n",
    "    GlobalBestAccuracy = ES_Optimized_ObjVal\n",
    "    NoImproveTimes = 0\n",
    "  else: \n",
    "    NoImproveTimes = NoImproveTimes + 1\n",
    "    if NoImproveTimes == 5:\n",
    "      break\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 66.84615384615384%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test) #X_train X_test\n",
    "y_pred = (y_pred > 0.5)  #y_pred 有 NA\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred) #y_train y_test\n",
    "\n",
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/sum(sum(cm)))*100))\n",
    "\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nw5YLWt3RtB6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "f5BM9m0lzRPv"
   ],
   "name": "ES_ANN_0508",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
