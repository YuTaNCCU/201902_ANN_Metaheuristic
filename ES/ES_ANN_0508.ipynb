{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ES_ANN_0501",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "f5BM9m0lzRPv"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuTaNCCU/201902_ANN_Metaheuristic/blob/master/ES/ES_ANN_0508.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JlwH6ajIzAuM"
      },
      "source": [
        "# Load Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rhYgessUEZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/YuTaNCCU/201902_ANN_Metaheuristic/tree/master/ES\n",
        "import random\n",
        "import pandas as pd\n",
        "from string import ascii_lowercase\n",
        "from copy import deepcopy\n",
        "from abc import ABCMeta, abstractmethod\n",
        "from copy import deepcopy\n",
        "from collections import deque\n",
        "from numpy import argmax\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential \n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNbHjxYPh0i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/YuTaNCCU/201902_ANN_Metaheuristic/master/Data/red.csv'\n",
        "red = pd.read_csv(url)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/YuTaNCCU/201902_ANN_Metaheuristic/master/Data/white.csv'\n",
        "white = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_keUw2Myjee2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red['WineCatg']='red'\n",
        "white['WineCatg']='white'\n",
        "Wine_Data = pd.concat([red, white])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBouGPm1iXRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2273
        },
        "outputId": "472a8a22-3d6f-43ae-c1aa-aae80adad650"
      },
      "source": [
        "display(\n",
        "    red.shape,\n",
        "  white.shape,\n",
        "  Wine_Data.shape,\n",
        "  Wine_Data\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1599, 13)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(4898, 13)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(6497, 13)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>WineCatg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>6</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.075</td>\n",
              "      <td>13.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.069</td>\n",
              "      <td>15.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.99640</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.065</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.99460</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.073</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>7</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.36</td>\n",
              "      <td>6.10</td>\n",
              "      <td>0.071</td>\n",
              "      <td>17.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.80</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.580</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.097</td>\n",
              "      <td>15.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.99590</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.36</td>\n",
              "      <td>6.10</td>\n",
              "      <td>0.071</td>\n",
              "      <td>17.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.80</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.089</td>\n",
              "      <td>16.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.99430</td>\n",
              "      <td>3.58</td>\n",
              "      <td>0.52</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.114</td>\n",
              "      <td>9.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.99740</td>\n",
              "      <td>3.26</td>\n",
              "      <td>1.56</td>\n",
              "      <td>9.100000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.18</td>\n",
              "      <td>3.80</td>\n",
              "      <td>0.176</td>\n",
              "      <td>52.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>0.99860</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.88</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.19</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.170</td>\n",
              "      <td>51.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>0.99860</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.93</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8.5</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.092</td>\n",
              "      <td>35.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.99690</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.75</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>7</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.368</td>\n",
              "      <td>16.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.11</td>\n",
              "      <td>1.28</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.08</td>\n",
              "      <td>4.40</td>\n",
              "      <td>0.086</td>\n",
              "      <td>6.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.99740</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.51</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.341</td>\n",
              "      <td>17.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.99690</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1.08</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>6</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.077</td>\n",
              "      <td>29.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.390</td>\n",
              "      <td>0.31</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.082</td>\n",
              "      <td>23.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.99820</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.21</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.106</td>\n",
              "      <td>10.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.99660</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.91</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8.5</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.11</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.084</td>\n",
              "      <td>9.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.14</td>\n",
              "      <td>2.40</td>\n",
              "      <td>0.085</td>\n",
              "      <td>21.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.43</td>\n",
              "      <td>0.63</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>6</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.390</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.080</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.99550</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.410</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.080</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.99620</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.59</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.21</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.106</td>\n",
              "      <td>10.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.99660</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.91</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.080</td>\n",
              "      <td>14.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.99720</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.55</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.082</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.99640</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.59</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>6</td>\n",
              "      <td>red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4868</th>\n",
              "      <td>5.8</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.31</td>\n",
              "      <td>4.50</td>\n",
              "      <td>0.046</td>\n",
              "      <td>42.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0.99324</td>\n",
              "      <td>3.31</td>\n",
              "      <td>0.64</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4869</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.33</td>\n",
              "      <td>10.10</td>\n",
              "      <td>0.032</td>\n",
              "      <td>8.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.99626</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.51</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4870</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.28</td>\n",
              "      <td>6.60</td>\n",
              "      <td>0.021</td>\n",
              "      <td>29.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.99188</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.36</td>\n",
              "      <td>11.450000</td>\n",
              "      <td>7</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4871</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.015</td>\n",
              "      <td>20.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98970</td>\n",
              "      <td>3.37</td>\n",
              "      <td>0.55</td>\n",
              "      <td>12.050000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4872</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.41</td>\n",
              "      <td>12.40</td>\n",
              "      <td>0.032</td>\n",
              "      <td>50.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>0.99622</td>\n",
              "      <td>3.14</td>\n",
              "      <td>0.60</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4873</th>\n",
              "      <td>5.7</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.030</td>\n",
              "      <td>33.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>0.99044</td>\n",
              "      <td>3.33</td>\n",
              "      <td>0.52</td>\n",
              "      <td>11.900000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4874</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.36</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.048</td>\n",
              "      <td>16.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>0.99282</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4875</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.035</td>\n",
              "      <td>18.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.99245</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0.41</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4876</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.380</td>\n",
              "      <td>0.42</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.038</td>\n",
              "      <td>34.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.99132</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.59</td>\n",
              "      <td>11.600000</td>\n",
              "      <td>7</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4877</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.032</td>\n",
              "      <td>12.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.99286</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>5</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4878</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.035</td>\n",
              "      <td>6.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.99234</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.35</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>4</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4879</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.40</td>\n",
              "      <td>8.10</td>\n",
              "      <td>0.046</td>\n",
              "      <td>68.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0.99494</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.533333</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4880</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.40</td>\n",
              "      <td>8.10</td>\n",
              "      <td>0.046</td>\n",
              "      <td>68.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0.99494</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.533333</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4881</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.27</td>\n",
              "      <td>11.75</td>\n",
              "      <td>0.030</td>\n",
              "      <td>34.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.99540</td>\n",
              "      <td>3.07</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4882</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.13</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.037</td>\n",
              "      <td>45.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>0.99184</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.38</td>\n",
              "      <td>10.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4883</th>\n",
              "      <td>4.9</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.035</td>\n",
              "      <td>60.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>0.98964</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.35</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4884</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.330</td>\n",
              "      <td>0.38</td>\n",
              "      <td>8.30</td>\n",
              "      <td>0.048</td>\n",
              "      <td>68.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.99492</td>\n",
              "      <td>3.14</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>5</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4885</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.40</td>\n",
              "      <td>8.10</td>\n",
              "      <td>0.046</td>\n",
              "      <td>68.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0.99494</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.550000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4886</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.28</td>\n",
              "      <td>5.70</td>\n",
              "      <td>0.028</td>\n",
              "      <td>45.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>0.99168</td>\n",
              "      <td>3.21</td>\n",
              "      <td>1.08</td>\n",
              "      <td>12.150000</td>\n",
              "      <td>7</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4887</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.410</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.023</td>\n",
              "      <td>5.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.98928</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.79</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4888</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.052</td>\n",
              "      <td>38.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>0.99330</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>5</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4889</th>\n",
              "      <td>4.9</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.27</td>\n",
              "      <td>11.75</td>\n",
              "      <td>0.030</td>\n",
              "      <td>34.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.99540</td>\n",
              "      <td>3.07</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4890</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.29</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.036</td>\n",
              "      <td>25.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.98938</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.44</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4891</th>\n",
              "      <td>5.7</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.038</td>\n",
              "      <td>38.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>0.99074</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.46</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4892</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.032</td>\n",
              "      <td>29.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.99298</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4893</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.00</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>5</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4895</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.290</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>7</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>6</td>\n",
              "      <td>white</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4             0.700         0.00            1.90      0.076   \n",
              "1               7.8             0.880         0.00            2.60      0.098   \n",
              "2               7.8             0.760         0.04            2.30      0.092   \n",
              "3              11.2             0.280         0.56            1.90      0.075   \n",
              "4               7.4             0.700         0.00            1.90      0.076   \n",
              "5               7.4             0.660         0.00            1.80      0.075   \n",
              "6               7.9             0.600         0.06            1.60      0.069   \n",
              "7               7.3             0.650         0.00            1.20      0.065   \n",
              "8               7.8             0.580         0.02            2.00      0.073   \n",
              "9               7.5             0.500         0.36            6.10      0.071   \n",
              "10              6.7             0.580         0.08            1.80      0.097   \n",
              "11              7.5             0.500         0.36            6.10      0.071   \n",
              "12              5.6             0.615         0.00            1.60      0.089   \n",
              "13              7.8             0.610         0.29            1.60      0.114   \n",
              "14              8.9             0.620         0.18            3.80      0.176   \n",
              "15              8.9             0.620         0.19            3.90      0.170   \n",
              "16              8.5             0.280         0.56            1.80      0.092   \n",
              "17              8.1             0.560         0.28            1.70      0.368   \n",
              "18              7.4             0.590         0.08            4.40      0.086   \n",
              "19              7.9             0.320         0.51            1.80      0.341   \n",
              "20              8.9             0.220         0.48            1.80      0.077   \n",
              "21              7.6             0.390         0.31            2.30      0.082   \n",
              "22              7.9             0.430         0.21            1.60      0.106   \n",
              "23              8.5             0.490         0.11            2.30      0.084   \n",
              "24              6.9             0.400         0.14            2.40      0.085   \n",
              "25              6.3             0.390         0.16            1.40      0.080   \n",
              "26              7.6             0.410         0.24            1.80      0.080   \n",
              "27              7.9             0.430         0.21            1.60      0.106   \n",
              "28              7.1             0.710         0.00            1.90      0.080   \n",
              "29              7.8             0.645         0.00            2.00      0.082   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "4868            5.8             0.230         0.31            4.50      0.046   \n",
              "4869            6.6             0.240         0.33           10.10      0.032   \n",
              "4870            6.1             0.320         0.28            6.60      0.021   \n",
              "4871            5.0             0.200         0.40            1.90      0.015   \n",
              "4872            6.0             0.420         0.41           12.40      0.032   \n",
              "4873            5.7             0.210         0.32            1.60      0.030   \n",
              "4874            5.6             0.200         0.36            2.50      0.048   \n",
              "4875            7.4             0.220         0.26            1.20      0.035   \n",
              "4876            6.2             0.380         0.42            2.50      0.038   \n",
              "4877            5.9             0.540         0.00            0.80      0.032   \n",
              "4878            6.2             0.530         0.02            0.90      0.035   \n",
              "4879            6.6             0.340         0.40            8.10      0.046   \n",
              "4880            6.6             0.340         0.40            8.10      0.046   \n",
              "4881            5.0             0.235         0.27           11.75      0.030   \n",
              "4882            5.5             0.320         0.13            1.30      0.037   \n",
              "4883            4.9             0.470         0.17            1.90      0.035   \n",
              "4884            6.5             0.330         0.38            8.30      0.048   \n",
              "4885            6.6             0.340         0.40            8.10      0.046   \n",
              "4886            6.2             0.210         0.28            5.70      0.028   \n",
              "4887            6.2             0.410         0.22            1.90      0.023   \n",
              "4888            6.8             0.220         0.36            1.20      0.052   \n",
              "4889            4.9             0.235         0.27           11.75      0.030   \n",
              "4890            6.1             0.340         0.29            2.20      0.036   \n",
              "4891            5.7             0.210         0.32            0.90      0.038   \n",
              "4892            6.5             0.230         0.38            1.30      0.032   \n",
              "4893            6.2             0.210         0.29            1.60      0.039   \n",
              "4894            6.6             0.320         0.36            8.00      0.047   \n",
              "4895            6.5             0.240         0.19            1.20      0.041   \n",
              "4896            5.5             0.290         0.30            1.10      0.022   \n",
              "4897            6.0             0.210         0.38            0.80      0.020   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "5                    13.0                  40.0  0.99780  3.51       0.56   \n",
              "6                    15.0                  59.0  0.99640  3.30       0.46   \n",
              "7                    15.0                  21.0  0.99460  3.39       0.47   \n",
              "8                     9.0                  18.0  0.99680  3.36       0.57   \n",
              "9                    17.0                 102.0  0.99780  3.35       0.80   \n",
              "10                   15.0                  65.0  0.99590  3.28       0.54   \n",
              "11                   17.0                 102.0  0.99780  3.35       0.80   \n",
              "12                   16.0                  59.0  0.99430  3.58       0.52   \n",
              "13                    9.0                  29.0  0.99740  3.26       1.56   \n",
              "14                   52.0                 145.0  0.99860  3.16       0.88   \n",
              "15                   51.0                 148.0  0.99860  3.17       0.93   \n",
              "16                   35.0                 103.0  0.99690  3.30       0.75   \n",
              "17                   16.0                  56.0  0.99680  3.11       1.28   \n",
              "18                    6.0                  29.0  0.99740  3.38       0.50   \n",
              "19                   17.0                  56.0  0.99690  3.04       1.08   \n",
              "20                   29.0                  60.0  0.99680  3.39       0.53   \n",
              "21                   23.0                  71.0  0.99820  3.52       0.65   \n",
              "22                   10.0                  37.0  0.99660  3.17       0.91   \n",
              "23                    9.0                  67.0  0.99680  3.17       0.53   \n",
              "24                   21.0                  40.0  0.99680  3.43       0.63   \n",
              "25                   11.0                  23.0  0.99550  3.34       0.56   \n",
              "26                    4.0                  11.0  0.99620  3.28       0.59   \n",
              "27                   10.0                  37.0  0.99660  3.17       0.91   \n",
              "28                   14.0                  35.0  0.99720  3.47       0.55   \n",
              "29                    8.0                  16.0  0.99640  3.38       0.59   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "4868                 42.0                 124.0  0.99324  3.31       0.64   \n",
              "4869                  8.0                  81.0  0.99626  3.19       0.51   \n",
              "4870                 29.0                 132.0  0.99188  3.15       0.36   \n",
              "4871                 20.0                  98.0  0.98970  3.37       0.55   \n",
              "4872                 50.0                 179.0  0.99622  3.14       0.60   \n",
              "4873                 33.0                 122.0  0.99044  3.33       0.52   \n",
              "4874                 16.0                 125.0  0.99282  3.49       0.49   \n",
              "4875                 18.0                  97.0  0.99245  3.12       0.41   \n",
              "4876                 34.0                 117.0  0.99132  3.36       0.59   \n",
              "4877                 12.0                  82.0  0.99286  3.25       0.36   \n",
              "4878                  6.0                  81.0  0.99234  3.24       0.35   \n",
              "4879                 68.0                 170.0  0.99494  3.15       0.50   \n",
              "4880                 68.0                 170.0  0.99494  3.15       0.50   \n",
              "4881                 34.0                 118.0  0.99540  3.07       0.50   \n",
              "4882                 45.0                 156.0  0.99184  3.26       0.38   \n",
              "4883                 60.0                 148.0  0.98964  3.27       0.35   \n",
              "4884                 68.0                 174.0  0.99492  3.14       0.50   \n",
              "4885                 68.0                 170.0  0.99494  3.15       0.50   \n",
              "4886                 45.0                 121.0  0.99168  3.21       1.08   \n",
              "4887                  5.0                  56.0  0.98928  3.04       0.79   \n",
              "4888                 38.0                 127.0  0.99330  3.04       0.54   \n",
              "4889                 34.0                 118.0  0.99540  3.07       0.50   \n",
              "4890                 25.0                 100.0  0.98938  3.06       0.44   \n",
              "4891                 38.0                 121.0  0.99074  3.24       0.46   \n",
              "4892                 29.0                 112.0  0.99298  3.29       0.54   \n",
              "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
              "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
              "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
              "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
              "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
              "\n",
              "        alcohol  quality WineCatg  \n",
              "0      9.400000        5      red  \n",
              "1      9.800000        5      red  \n",
              "2      9.800000        5      red  \n",
              "3      9.800000        6      red  \n",
              "4      9.400000        5      red  \n",
              "5      9.400000        5      red  \n",
              "6      9.400000        5      red  \n",
              "7     10.000000        7      red  \n",
              "8      9.500000        7      red  \n",
              "9     10.500000        5      red  \n",
              "10     9.200000        5      red  \n",
              "11    10.500000        5      red  \n",
              "12     9.900000        5      red  \n",
              "13     9.100000        5      red  \n",
              "14     9.200000        5      red  \n",
              "15     9.200000        5      red  \n",
              "16    10.500000        7      red  \n",
              "17     9.300000        5      red  \n",
              "18     9.000000        4      red  \n",
              "19     9.200000        6      red  \n",
              "20     9.400000        6      red  \n",
              "21     9.700000        5      red  \n",
              "22     9.500000        5      red  \n",
              "23     9.400000        5      red  \n",
              "24     9.700000        6      red  \n",
              "25     9.300000        5      red  \n",
              "26     9.500000        5      red  \n",
              "27     9.500000        5      red  \n",
              "28     9.400000        5      red  \n",
              "29     9.800000        6      red  \n",
              "...         ...      ...      ...  \n",
              "4868  10.800000        6    white  \n",
              "4869   9.800000        6    white  \n",
              "4870  11.450000        7    white  \n",
              "4871  12.050000        6    white  \n",
              "4872   9.700000        5    white  \n",
              "4873  11.900000        6    white  \n",
              "4874  10.000000        6    white  \n",
              "4875   9.700000        6    white  \n",
              "4876  11.600000        7    white  \n",
              "4877   8.800000        5    white  \n",
              "4878   9.500000        4    white  \n",
              "4879   9.533333        6    white  \n",
              "4880   9.533333        6    white  \n",
              "4881   9.400000        6    white  \n",
              "4882  10.700000        5    white  \n",
              "4883  11.500000        6    white  \n",
              "4884   9.600000        5    white  \n",
              "4885   9.550000        6    white  \n",
              "4886  12.150000        7    white  \n",
              "4887  13.000000        7    white  \n",
              "4888   9.200000        5    white  \n",
              "4889   9.400000        6    white  \n",
              "4890  11.800000        6    white  \n",
              "4891  10.600000        6    white  \n",
              "4892   9.700000        5    white  \n",
              "4893  11.200000        6    white  \n",
              "4894   9.600000        5    white  \n",
              "4895   9.400000        6    white  \n",
              "4896  12.800000        7    white  \n",
              "4897  11.800000        6    white  \n",
              "\n",
              "[6497 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isg-ogGRUHat",
        "colab_type": "text"
      },
      "source": [
        "# Define ES class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu47m1CnUrM1",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "class ES:\n",
        "    \"\"\"\n",
        "    Conducts tabu search\n",
        "    \"\"\"\n",
        "    __metaclass__ = ABCMeta\n",
        "\n",
        "    #default hyper parameters\n",
        "    InitialSigma = None\n",
        "    ParentsSize = None\n",
        "    ChildSize = None\n",
        "    tao = None\n",
        "    \n",
        "    #for input/output\n",
        "    KerasModels = None\n",
        "    WeightsStrucure = None   \n",
        "    weights = None\n",
        "    \n",
        "    #for record\n",
        "    cur_steps = 1\n",
        "    best_weight = None\n",
        "    best_score = None\n",
        "    \n",
        "    UseOLSReg=None\n",
        "    X_train=None\n",
        "    y_train=None\n",
        "    \n",
        "    def __init__(self, KerasModels, X_train, y_train, UseOLSReg=False, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5):\n",
        "        \"\"\"\n",
        "        :param KerasModels: a Keras model, like keras.engine.sequential.Sequential\n",
        "        :param weights: initial weights, should be a Keras model weight\n",
        "        :param max_steps: maximum number of steps to run algorithm for\n",
        "        :param UseOLSReg: If True, than use \"OLS Regression\" for the last layer\n",
        "        \n",
        "        \"\"\"\n",
        "        self.KerasModels = KerasModels\n",
        "        \n",
        "        self.UseOLSReg = UseOLSReg\n",
        "        \n",
        "        self.X_train=X_train\n",
        "        self.y_train=y_train\n",
        " \n",
        "        if all(isinstance(x, float) for x in [InitialSigma, tao]) and all(x > 0 for x in [InitialSigma, tao]):\n",
        "            self.InitialSigma = InitialSigma\n",
        "            self.tao = tao\n",
        "        else:\n",
        "            raise TypeError('InitialSigma & tao must be a positive float')\n",
        "            \n",
        "        if all(isinstance(x, int) for x in [ParentsSize, ChildSize]) and all(x > 0 for x in [ParentsSize, ChildSize]):\n",
        "            self.ParentsSize = ParentsSize\n",
        "            self.ChildSize = ChildSize\n",
        "        else:\n",
        "            raise TypeError('ParentsSize, ChildSize & max_steps must be a positive integer')\n",
        "\n",
        "    def __str__(self): \n",
        "        return ('ES STEPS: %d ' +\n",
        "                'BEST SCORE: %.4f ') % \\\n",
        "               (self.cur_steps, self.best_score)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__() \n",
        "    \n",
        "    def _FlattenWeights(self, weights):\n",
        "        \"\"\"\n",
        "        flatten weights\n",
        "        \n",
        "        param weights: keras神經網路的權重格式:nparray包在list中\n",
        "        return WeightsStrucure : 神經網路各層的權重shape包在list中，unflatten時會用到\n",
        "        return FlattenedWeights : 一維list包含所有的權重\n",
        "        \"\"\"\n",
        "        WeightsStrucure = []\n",
        "        FlattenedWeights = []\n",
        "        for i_layer in weights:\n",
        "            WeightsStrucure.append(i_layer.shape)\n",
        "            if len(i_layer.shape) == 1 :# 該層權重的shape為一維 e.g. (15,)      \n",
        "                FlattenedWeights.extend(i_layer)\n",
        "            else :# 該層權重的shape為二維 e.g. (30, 15)  \n",
        "                for i_links in i_layer:\n",
        "                    FlattenedWeights.extend(i_links)\n",
        "        return WeightsStrucure, FlattenedWeights\n",
        "\n",
        "    def _UnflattenWeights(self, WeightsStrucure, ModifiedWeights):\n",
        "        \"\"\"\n",
        "        Unflatten(回復成原本的結構) weights  \n",
        "        \n",
        "        param WeightsStrucure : 神經網路各層的權重shape包在list中\n",
        "        param ModifiedWeights : 一維list包含所有meteHeuristic修改過的權重\n",
        "        return: keras神經網路的權重格式:nparray包在list中\n",
        "        \"\"\"\n",
        "        UnflattenWeights = []\n",
        "        i_index = 0 \n",
        "        for i_layer in WeightsStrucure:\n",
        "            if len(i_layer) == 1 : # 該層權重的shape為一維 e.g. (15,)      \n",
        "                TempList = ModifiedWeights[i_index:(i_index + i_layer[0])]\n",
        "                TempList = np.asarray(TempList)\n",
        "                i_index = i_index + i_layer[0]\n",
        "            else : # 該層權重的shape為二維 e.g. (30, 15)  \n",
        "                TempList = ModifiedWeights[i_index:(i_index + (i_layer[0]*i_layer[1]))]\n",
        "                TempList = np.reshape(TempList, i_layer )\n",
        "                i_index = i_index + (i_layer[0]*i_layer[1])\n",
        "            UnflattenWeights.append(TempList)\n",
        "        return UnflattenWeights   \n",
        "    \n",
        "    def _best(self, Population_Child_score):\n",
        "        \"\"\"\n",
        "        Finds the best member of a neighborhood\n",
        "        :param Population_Child_score: a np array\n",
        "        :return: the indtex of N best member, N = ParentsSize\n",
        "        \"\"\"\n",
        "        return np.array( Population_Child_score ).argsort()[::-1][:self.ParentsSize]\n",
        "    \n",
        "    def _Recombination(self, Population_Parents_Weights, Population_Parents_Sigma, rows): #GenerateParents\n",
        "        \"\"\"\n",
        "        Generate New Parents Polulation\n",
        "        \"\"\"\n",
        "        Population_Weights_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
        "        Population_Sigma_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
        "        for index_row, _ in enumerate( Population_Weights_Recombination ):\n",
        "            \"\"\"\n",
        "            可能可以平行計算\n",
        "            \"\"\"\n",
        "            TwoRowschoiced = np.random.choice(Population_Parents_Weights.shape[0], size=2, replace=False,)\n",
        "            Parent1Mask = np.random.randint(2, size=Population_Parents_Weights.shape[1])\n",
        "            Parent2Mask = np.full(shape = Population_Parents_Weights.shape[1], fill_value = 1 )  - Parent1Mask\n",
        "            \n",
        "            Population_Weights_Recombination[index_row,:] = (Population_Parents_Weights[TwoRowschoiced] * [Parent1Mask, Parent2Mask]).sum(axis=0)\n",
        "            Population_Sigma_Recombination[index_row,:] = Population_Parents_Sigma[TwoRowschoiced].mean(axis=0)\n",
        "        return Population_Weights_Recombination, Population_Sigma_Recombination\n",
        "\n",
        "    def _score(self, ModifiedWeights):\n",
        "        \n",
        "        \"\"\"\n",
        "        Returns objective function value of a state\n",
        "\n",
        "        :param state: a state\n",
        "        :return: objective function value of state\n",
        "        \"\"\"\n",
        "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
        "        self.KerasModels.set_weights(UnflattenedWeights)\n",
        "        test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
        "        return test_on_batch[1]\n",
        "    #==================\n",
        "        #==================\n",
        "          #==================\n",
        "            #==================\n",
        "    def _OLSReg(self, ModifiedWeights):\n",
        "        \n",
        "        \"\"\"\n",
        "        :param : \n",
        "        :return: Keras Models, objective function value of state\n",
        "        \"\"\"\n",
        "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
        "        \n",
        "        #%% OLS Regression\n",
        "        #obtain the output of an intermediate layer\n",
        "        #https://keras.io/getting-started/faq/?fbclid=IwAR3Zv35V-vmEy85anudOrlxCExXYwyG6cRL1UR0AaLPU6sZEoBjsbX-8LXQ#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
        "        self.KerasModels.set_weights(UnflattenedWeights)\n",
        "        layer_name = 'IntermediateLayer'\n",
        "        intermediate_layer_model = keras_models_Model(inputs=self.KerasModels.input,\n",
        "                                         outputs=self.KerasModels.get_layer(layer_name).output)\n",
        "        intermediate_output = intermediate_layer_model.predict(self.X_train)\n",
        "\n",
        "        #fit LM\n",
        "        lm =  LogisticRegression(random_state=0, solver='liblinear').fit(intermediate_output, self.y_train)\n",
        "        \n",
        "        #lm =  LinearRegression().fit(intermediate_output, self.y_train)\n",
        "        # 印出係數, 截距 print(lm.coef_, lm.intercept_)\n",
        "        \n",
        "        #score\n",
        "        #score = log_loss(y_pred = lm.predict(intermediate_output), y_true= self.y_train)\n",
        "        \n",
        "        #get OutLayerWeights\n",
        "        OutLayerWeights = [np.array(lm.coef_).reshape(self.WeightsStrucure[-2]),\n",
        "                           np.array(lm.intercept_).reshape(self.WeightsStrucure[-1])]\n",
        "\n",
        "        #update ES-optimized weights\n",
        "        UnflattenedWeights[-2:] = OutLayerWeights        \n",
        "        \n",
        "        #self.KerasModels.set_weights(UnflattenedWeights)\n",
        "        #test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
        "        \n",
        "        #print( 'score',score, 'test_on_batch',test_on_batch)\n",
        "        _, OLS_Optimized_Weight = self._FlattenWeights(UnflattenedWeights)\n",
        "        return OLS_Optimized_Weight \n",
        "\n",
        "    def run(self, weights, max_steps=5, verbose=10, useOLSReg = False):\n",
        "        \"\"\"\n",
        "        Conducts ES\n",
        "        :param weights: \n",
        "        :param max_steps: \n",
        "        :param verbose: int which indicates how many iter to show score\n",
        "        :return: Keras Models, best state and objective function value of best state\n",
        "        \"\"\"\n",
        "        \n",
        "        if isinstance(weights, list)  :\n",
        "          \n",
        "            self.WeightsStrucure, self.weights = self._FlattenWeights(weights)\n",
        "            self.best_weight = self.weights\n",
        "            self.best_score = self._score(self.best_weight)\n",
        "        else:\n",
        "            raise TypeError('initial_state must be a list') \n",
        "            \n",
        "        self.max_steps = max_steps\n",
        "        \n",
        "        #Step1 initial             \n",
        "        Population_Parents_Weights = np.array([self.weights, self.weights])         \n",
        "        Population_Parents_Sigma = np.full(shape = (self.ParentsSize, len(self.weights)), fill_value = self.InitialSigma ) \n",
        "        Population_Parents_Weights, _ = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ParentsSize )\n",
        "        self.cur_steps = 1\n",
        "        while True:   \n",
        "            #Step2 Child\n",
        "            ##Discrete Recombination\n",
        "            Population_Child_Weights, Population_Child_Sigma = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ChildSize )\n",
        "            ##mutation1\n",
        "            RamdonNormalValue = np.random.normal(0, 1, 1)\n",
        "            RamdonNormalValueDifferent = np.random.normal(0, 1, Population_Child_Sigma.shape)\n",
        "            Population_Child_Sigma = np.exp( (1-self.tao)*RamdonNormalValue + self.tao*RamdonNormalValueDifferent )\n",
        "            ##mutation2\n",
        "            Population_Child_Weights = Population_Child_Weights + np.random.normal(0, Population_Child_Sigma, Population_Child_Sigma.shape)\n",
        "            \n",
        "            \n",
        "            # OLS Regression\n",
        "            if useOLSReg == True:\n",
        "              for i, i_Child in enumerate(Population_Child_Weights) :\n",
        "                  OLS_Optimized_Weight = self._OLSReg(i_Child)\n",
        "                  #print(OLS_Optimized_Weight,'i:\\n', i, Population_Child_Weights[i])\n",
        "                  Population_Child_Weights[i] = OLS_Optimized_Weight\n",
        "            \n",
        "            \n",
        "            #step3 Evaluation\n",
        "            Population_Child_score = []\n",
        "            for i_Child in Population_Child_Weights :\n",
        "                \"\"\"\n",
        "                可能可以平行計算\n",
        "                \"\"\"\n",
        "                Population_Child_score.append( self._score(i_Child) )\n",
        "                 \n",
        "            BestNIndex = self._best(Population_Child_score)\n",
        "            Population_Parents_Weights = Population_Child_Weights[BestNIndex,:]\n",
        "            Population_Parents_Sigma = Population_Child_Sigma[BestNIndex,:]\n",
        "            \n",
        "            #更新best\n",
        "            best_weight_This_Iter =  Population_Child_Weights[BestNIndex,:][0]\n",
        "            best_score_This_Iter = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
        "            if best_score_This_Iter > self.best_score:\n",
        "                self.best_weight =  Population_Child_Weights[BestNIndex,:][0]\n",
        "                self.best_score = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
        "        \n",
        "            #print process \n",
        "            if ((self.cur_steps ) % verbose == 0) and verbose:\n",
        "               print(self)\n",
        "                \n",
        "            self.cur_steps = self.cur_steps + 1\n",
        "            #step4 check stop criteria\n",
        "            if self.cur_steps > max_steps:\n",
        "                print( 'Stop: Reach max_steps' )\n",
        "                break\n",
        "        return self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = self.best_weight), self.best_score \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkGYn2e523KP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UR8bAYdozEEv"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqQvjI11U0zb",
        "colab_type": "code",
        "outputId": "7b7a614c-0a63-4a1e-ff8e-1c1169b5dc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "#資料集是以dictionary的形式存在\n",
        "cancer = load_breast_cancer()\n",
        "df_feat = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
        "\n",
        "X = df_feat.iloc[:, ].values\n",
        "y = cancer['target']\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "y = labelencoder_X_1.fit_transform(y)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "#Feature Scaling\n",
        "\"\"\"from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\"\"\"\n",
        "\n",
        "#X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from sklearn.preprocessing import StandardScaler\\nsc = StandardScaler()\\nX_train = sc.fit_transform(X_train)\\nX_test = sc.transform(X_test)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LgjIusZlzDaT"
      },
      "source": [
        "# Model Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBrIxe5CU5Nz",
        "colab_type": "code",
        "outputId": "14928888-e0d9-4fd6-ec41-68f80f096506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, Model as keras_models_Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(30,)))\n",
        "#model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(3, activation='relu', name = 'IntermediateLayer'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "IntermediateLayer (Dense)    (None, 3)                 33        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 347\n",
            "Trainable params: 347\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5BM9m0lzRPv",
        "colab_type": "text"
      },
      "source": [
        "# OLS Regression TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ExSfXBU61J",
        "colab_type": "code",
        "outputId": "7d979c2c-abc8-4395-ab4e-06db94f8c7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "def _FlattenWeights(weights):\n",
        "    \"\"\"\n",
        "    flatten weights\n",
        "\n",
        "    param weights: keras神經網路的權重格式:nparray包在list中\n",
        "    return WeightsStrucure : 神經網路各層的權重shape包在list中，unflatten時會用到\n",
        "    return FlattenedWeights : 一維list包含所有的權重\n",
        "    \"\"\"\n",
        "    WeightsStrucure = []\n",
        "    FlattenedWeights = []\n",
        "    for i_layer in weights:\n",
        "        WeightsStrucure.append(i_layer.shape)\n",
        "        if len(i_layer.shape) == 1 :# 該層權重的shape為一維 e.g. (15,)      \n",
        "            FlattenedWeights.extend(i_layer)\n",
        "        else :# 該層權重的shape為二維 e.g. (30, 15)  \n",
        "            for i_links in i_layer:\n",
        "                FlattenedWeights.extend(i_links)\n",
        "    return WeightsStrucure, FlattenedWeights\n",
        "a,b=_FlattenWeights(weights)\n",
        "a[-2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyHeRtjbfp_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#weights[-2:] = weights[-2:]*0\n",
        "display(\n",
        "    'WeightsStrucure==========='\n",
        "    , WeightsStrucure\n",
        "    , 'WeightsStrucure[-2:]==========='\n",
        "    , WeightsStrucure[-2:] #最後一層的weights 及 bias\n",
        "    , 'weights==========='\n",
        "    , weights\n",
        "    , 'weights[-2:]==========='\n",
        "    , weights[-2:]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsZOKrqgjS-0",
        "colab_type": "code",
        "outputId": "0d861ce2-7317-4730-c47e-31736709d8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "#%% OLS Regression\n",
        "#obtain the output of an intermediate layer\n",
        "#https://keras.io/getting-started/faq/?fbclid=IwAR3Zv35V-vmEy85anudOrlxCExXYwyG6cRL1UR0AaLPU6sZEoBjsbX-8LXQ#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
        "layer_name = 'IntermediateLayer'\n",
        "intermediate_layer_model = keras_models_Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "\n",
        "\n",
        "#fit LM\n",
        "lm = LinearRegression().fit(intermediate_output, y_train)\n",
        "# 印出係數, 截距 print(lm.coef_, lm.intercept_)\n",
        "\n",
        "#score\n",
        "score = log_loss(y_pred = lm.predict(intermediate_output), y_true= y_train)\n",
        "\n",
        "\n",
        "\n",
        "OutLayerWeights = [np.array(lm.coef_).reshape((3,1)), np.array(lm.intercept_).reshape((1))]\n",
        "\n",
        "#update ES-optimized weights\n",
        "weights[-2:] = OutLayerWeights        \n",
        "\n",
        "model.set_weights(weights)\n",
        "test_on_batch = model.test_on_batch(X_train, y_train, sample_weight=None) # return ['loss', 'acc']\n",
        "\n",
        "print( 'score',score, 'test_on_batch[1]',test_on_batch[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score nan test_on_batch[1] 0.6505495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1817: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1817: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-V1mlLBha5I",
        "colab": {}
      },
      "source": [
        "weights[-2:] = OutLayerWeights\n",
        "display(\n",
        "    'WeightsStrucure==========='\n",
        "    , WeightsStrucure\n",
        "    , 'WeightsStrucure[-2:]==========='\n",
        "    , WeightsStrucure[-2:] #最後一層的weights 及 bias\n",
        "    , 'weights==========='\n",
        "    , weights\n",
        "    , 'weights[-2:]==========='\n",
        "    , weights[-2:]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULIddEh0zWGU",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE_V_96FU9yy",
        "colab_type": "code",
        "outputId": "13503c1e-ff7a-4064-f97e-359f6a60818a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1884
        }
      },
      "source": [
        "# Initialize\n",
        "weights = model.get_weights() \n",
        "MyES = ES(model, X_train, y_train, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5)   \n",
        "weights, ES_Optimized_ObjVal  = MyES.run(weights, useOLSReg =True, max_steps=3, verbose = 1)\n",
        "\n",
        "# Optimize\n",
        "GlobalBestAccuracy = 0\n",
        "NoImproveTimes = 0\n",
        "while True:\n",
        "  # Gradient-based Optimize\n",
        "  model.set_weights(weights)\n",
        "  model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
        "  weights = model.get_weights() \n",
        "\n",
        "  # ES\n",
        "  weights, ES_Optimized_ObjVal  = MyES.run(weights, max_steps=5, verbose = 1)\n",
        "  \n",
        "  # Stop Criteria\n",
        "  if ES_Optimized_ObjVal > GlobalBestAccuracy:\n",
        "    GlobalBestAccuracy = ES_Optimized_ObjVal\n",
        "    NoImproveTimes = 0\n",
        "  else: \n",
        "    NoImproveTimes = NoImproveTimes + 1\n",
        "    if NoImproveTimes == 5:\n",
        "      break\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ES STEPS: 1 BEST SCORE: 0.9363 \n",
            "ES STEPS: 2 BEST SCORE: 0.9363 \n",
            "ES STEPS: 3 BEST SCORE: 0.9363 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 53us/step - loss: 5.4052 - acc: 0.6571\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 51us/step - loss: 5.7813 - acc: 0.6374\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 55us/step - loss: 5.7813 - acc: 0.6374\n",
            "ES STEPS: 1 BEST SCORE: 0.8967 \n",
            "ES STEPS: 2 BEST SCORE: 0.9187 \n",
            "ES STEPS: 3 BEST SCORE: 0.9231 \n",
            "ES STEPS: 4 BEST SCORE: 0.9231 \n",
            "ES STEPS: 5 BEST SCORE: 0.9231 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8703 - acc: 0.9231\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 57us/step - loss: 0.8701 - acc: 0.9231\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.8698 - acc: 0.9231\n",
            "ES STEPS: 1 BEST SCORE: 0.9275 \n",
            "ES STEPS: 2 BEST SCORE: 0.9275 \n",
            "ES STEPS: 3 BEST SCORE: 0.9275 \n",
            "ES STEPS: 4 BEST SCORE: 0.9275 \n",
            "ES STEPS: 5 BEST SCORE: 0.9275 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.7469 - acc: 0.9297\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8420 - acc: 0.9187\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 51us/step - loss: 0.8860 - acc: 0.9121\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 45us/step - loss: 0.8326 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8322 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 53us/step - loss: 0.8318 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 56us/step - loss: 0.8314 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8310 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8306 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.8302 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 74us/step - loss: 0.8298 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8294 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8290 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8286 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 58us/step - loss: 0.8283 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8279 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 63us/step - loss: 0.8275 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 60us/step - loss: 0.8272 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw5YLWt3RtB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}