{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ES_ANN_0501",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "f5BM9m0lzRPv"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuTaNCCU/201902_ANN_Metaheuristic/blob/master/ES/ES_ANN_0501.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JlwH6ajIzAuM"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Package"
      ]
    },
    {
      "metadata": {
        "id": "-rhYgessUEZb",
        "colab_type": "code",
        "outputId": "e0285ea0-ac09-4d21-e4e7-2a60d2a99528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "#https://github.com/YuTaNCCU/201902_ANN_Metaheuristic/tree/master/ES\n",
        "import random\n",
        "from string import ascii_lowercase\n",
        "from copy import deepcopy\n",
        "from abc import ABCMeta, abstractmethod\n",
        "from copy import deepcopy\n",
        "from collections import deque\n",
        "from numpy import argmax\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential \n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "isg-ogGRUHat",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define ES class"
      ]
    },
    {
      "metadata": {
        "id": "Eu47m1CnUrM1",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ES:\n",
        "    \"\"\"\n",
        "    Conducts tabu search\n",
        "    \"\"\"\n",
        "    __metaclass__ = ABCMeta\n",
        "\n",
        "    #default hyper parameters\n",
        "    InitialSigma = None\n",
        "    ParentsSize = None\n",
        "    ChildSize = None\n",
        "    tao = None\n",
        "    \n",
        "    #for input/output\n",
        "    KerasModels = None\n",
        "    WeightsStrucure = None   \n",
        "    weights = None\n",
        "    \n",
        "    #for record\n",
        "    cur_steps = 1\n",
        "    best_weight = None\n",
        "    best_score = None\n",
        "    \n",
        "    UseOLSReg=None\n",
        "    X_train=None\n",
        "    y_train=None\n",
        "    \n",
        "    def __init__(self, KerasModels, X_train, y_train, UseOLSReg=False, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5):\n",
        "        \"\"\"\n",
        "        :param KerasModels: a Keras model, like keras.engine.sequential.Sequential\n",
        "        :param weights: initial weights, should be a Keras model weight\n",
        "        :param max_steps: maximum number of steps to run algorithm for\n",
        "        :param UseOLSReg: If True, than use \"OLS Regression\" for the last layer\n",
        "        \n",
        "        \"\"\"\n",
        "        self.KerasModels = KerasModels\n",
        "        \n",
        "        self.UseOLSReg = UseOLSReg\n",
        "        \n",
        "        self.X_train=X_train\n",
        "        self.y_train=y_train\n",
        " \n",
        "        if all(isinstance(x, float) for x in [InitialSigma, tao]) and all(x > 0 for x in [InitialSigma, tao]):\n",
        "            self.InitialSigma = InitialSigma\n",
        "            self.tao = tao\n",
        "        else:\n",
        "            raise TypeError('InitialSigma & tao must be a positive float')\n",
        "            \n",
        "        if all(isinstance(x, int) for x in [ParentsSize, ChildSize]) and all(x > 0 for x in [ParentsSize, ChildSize]):\n",
        "            self.ParentsSize = ParentsSize\n",
        "            self.ChildSize = ChildSize\n",
        "        else:\n",
        "            raise TypeError('ParentsSize, ChildSize & max_steps must be a positive integer')\n",
        "\n",
        "    def __str__(self): \n",
        "        return ('ES STEPS: %d ' +\n",
        "                'BEST SCORE: %.4f ') % \\\n",
        "               (self.cur_steps, self.best_score)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__() \n",
        "    \n",
        "    def _FlattenWeights(self, weights):\n",
        "        \"\"\"\n",
        "        flatten weights\n",
        "        \n",
        "        param weights: keras神經網路的權重格式:nparray包在list中\n",
        "        return WeightsStrucure : 神經網路各層的權重shape包在list中，unflatten時會用到\n",
        "        return FlattenedWeights : 一維list包含所有的權重\n",
        "        \"\"\"\n",
        "        WeightsStrucure = []\n",
        "        FlattenedWeights = []\n",
        "        for i_layer in weights:\n",
        "            WeightsStrucure.append(i_layer.shape)\n",
        "            if len(i_layer.shape) == 1 :# 該層權重的shape為一維 e.g. (15,)      \n",
        "                FlattenedWeights.extend(i_layer)\n",
        "            else :# 該層權重的shape為二維 e.g. (30, 15)  \n",
        "                for i_links in i_layer:\n",
        "                    FlattenedWeights.extend(i_links)\n",
        "        return WeightsStrucure, FlattenedWeights\n",
        "\n",
        "    def _UnflattenWeights(self, WeightsStrucure, ModifiedWeights):\n",
        "        \"\"\"\n",
        "        Unflatten(回復成原本的結構) weights  \n",
        "        \n",
        "        param WeightsStrucure : 神經網路各層的權重shape包在list中\n",
        "        param ModifiedWeights : 一維list包含所有meteHeuristic修改過的權重\n",
        "        return: keras神經網路的權重格式:nparray包在list中\n",
        "        \"\"\"\n",
        "        UnflattenWeights = []\n",
        "        i_index = 0 \n",
        "        for i_layer in WeightsStrucure:\n",
        "            if len(i_layer) == 1 : # 該層權重的shape為一維 e.g. (15,)      \n",
        "                TempList = ModifiedWeights[i_index:(i_index + i_layer[0])]\n",
        "                TempList = np.asarray(TempList)\n",
        "                i_index = i_index + i_layer[0]\n",
        "            else : # 該層權重的shape為二維 e.g. (30, 15)  \n",
        "                TempList = ModifiedWeights[i_index:(i_index + (i_layer[0]*i_layer[1]))]\n",
        "                TempList = np.reshape(TempList, i_layer )\n",
        "                i_index = i_index + (i_layer[0]*i_layer[1])\n",
        "            UnflattenWeights.append(TempList)\n",
        "        return UnflattenWeights   \n",
        "    \n",
        "    def _best(self, Population_Child_score):\n",
        "        \"\"\"\n",
        "        Finds the best member of a neighborhood\n",
        "        :param Population_Child_score: a np array\n",
        "        :return: the indtex of N best member, N = ParentsSize\n",
        "        \"\"\"\n",
        "        return np.array( Population_Child_score ).argsort()[::-1][:self.ParentsSize]\n",
        "    \n",
        "    def _Recombination(self, Population_Parents_Weights, Population_Parents_Sigma, rows): #GenerateParents\n",
        "        \"\"\"\n",
        "        Generate New Parents Polulation\n",
        "        \"\"\"\n",
        "        Population_Weights_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
        "        Population_Sigma_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
        "        for index_row, _ in enumerate( Population_Weights_Recombination ):\n",
        "            \"\"\"\n",
        "            可能可以平行計算\n",
        "            \"\"\"\n",
        "            TwoRowschoiced = np.random.choice(Population_Parents_Weights.shape[0], size=2, replace=False,)\n",
        "            Parent1Mask = np.random.randint(2, size=Population_Parents_Weights.shape[1])\n",
        "            Parent2Mask = np.full(shape = Population_Parents_Weights.shape[1], fill_value = 1 )  - Parent1Mask\n",
        "            \n",
        "            Population_Weights_Recombination[index_row,:] = (Population_Parents_Weights[TwoRowschoiced] * [Parent1Mask, Parent2Mask]).sum(axis=0)\n",
        "            Population_Sigma_Recombination[index_row,:] = Population_Parents_Sigma[TwoRowschoiced].mean(axis=0)\n",
        "        return Population_Weights_Recombination, Population_Sigma_Recombination\n",
        "\n",
        "    def _score(self, ModifiedWeights):\n",
        "        \n",
        "        \"\"\"\n",
        "        Returns objective function value of a state\n",
        "\n",
        "        :param state: a state\n",
        "        :return: objective function value of state\n",
        "        \"\"\"\n",
        "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
        "        self.KerasModels.set_weights(UnflattenedWeights)\n",
        "        test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
        "        return test_on_batch[1]\n",
        "    #==================\n",
        "        #==================\n",
        "          #==================\n",
        "            #==================\n",
        "    def _OLSReg(self, ModifiedWeights):\n",
        "        \n",
        "        \"\"\"\n",
        "        :param : \n",
        "        :return: Keras Models, objective function value of state\n",
        "        \"\"\"\n",
        "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
        "        \n",
        "        #%% OLS Regression\n",
        "        #obtain the output of an intermediate layer\n",
        "        #https://keras.io/getting-started/faq/?fbclid=IwAR3Zv35V-vmEy85anudOrlxCExXYwyG6cRL1UR0AaLPU6sZEoBjsbX-8LXQ#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
        "        self.KerasModels.set_weights(UnflattenedWeights)\n",
        "        layer_name = 'IntermediateLayer'\n",
        "        intermediate_layer_model = keras_models_Model(inputs=self.KerasModels.input,\n",
        "                                         outputs=self.KerasModels.get_layer(layer_name).output)\n",
        "        intermediate_output = intermediate_layer_model.predict(self.X_train)\n",
        "\n",
        "        #fit LM\n",
        "        lm =  LogisticRegression(random_state=0, solver='liblinear').fit(intermediate_output, self.y_train)\n",
        "        \n",
        "        #lm =  LinearRegression().fit(intermediate_output, self.y_train)\n",
        "        # 印出係數, 截距 print(lm.coef_, lm.intercept_)\n",
        "        \n",
        "        #score\n",
        "        #score = log_loss(y_pred = lm.predict(intermediate_output), y_true= self.y_train)\n",
        "        \n",
        "        #get OutLayerWeights\n",
        "        OutLayerWeights = [np.array(lm.coef_).reshape(self.WeightsStrucure[-2]),\n",
        "                           np.array(lm.intercept_).reshape(self.WeightsStrucure[-1])]\n",
        "\n",
        "        #update ES-optimized weights\n",
        "        UnflattenedWeights[-2:] = OutLayerWeights        \n",
        "        \n",
        "        #self.KerasModels.set_weights(UnflattenedWeights)\n",
        "        #test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
        "        \n",
        "        #print( 'score',score, 'test_on_batch',test_on_batch)\n",
        "        _, OLS_Optimized_Weight = self._FlattenWeights(UnflattenedWeights)\n",
        "        return OLS_Optimized_Weight \n",
        "\n",
        "    def run(self, weights, max_steps=5, verbose=10, useOLSReg = False):\n",
        "        \"\"\"\n",
        "        Conducts ES\n",
        "        :param weights: \n",
        "        :param max_steps: \n",
        "        :param verbose: int which indicates how many iter to show score\n",
        "        :return: Keras Models, best state and objective function value of best state\n",
        "        \"\"\"\n",
        "        \n",
        "        if isinstance(weights, list)  :\n",
        "          \n",
        "            self.WeightsStrucure, self.weights = self._FlattenWeights(weights)\n",
        "            self.best_weight = self.weights\n",
        "            self.best_score = self._score(self.best_weight)\n",
        "        else:\n",
        "            raise TypeError('initial_state must be a list') \n",
        "            \n",
        "        self.max_steps = max_steps\n",
        "        \n",
        "        #Step1 initial             \n",
        "        Population_Parents_Weights = np.array([self.weights, self.weights])         \n",
        "        Population_Parents_Sigma = np.full(shape = (self.ParentsSize, len(self.weights)), fill_value = self.InitialSigma ) \n",
        "        Population_Parents_Weights, _ = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ParentsSize )\n",
        "        self.cur_steps = 1\n",
        "        while True:   \n",
        "            #Step2 Child\n",
        "            ##Discrete Recombination\n",
        "            Population_Child_Weights, Population_Child_Sigma = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ChildSize )\n",
        "            ##mutation1\n",
        "            RamdonNormalValue = np.random.normal(0, 1, 1)\n",
        "            RamdonNormalValueDifferent = np.random.normal(0, 1, Population_Child_Sigma.shape)\n",
        "            Population_Child_Sigma = np.exp( (1-self.tao)*RamdonNormalValue + self.tao*RamdonNormalValueDifferent )\n",
        "            ##mutation2\n",
        "            Population_Child_Weights = Population_Child_Weights + np.random.normal(0, Population_Child_Sigma, Population_Child_Sigma.shape)\n",
        "            \n",
        "            \n",
        "            # OLS Regression\n",
        "            if useOLSReg == True:\n",
        "              for i, i_Child in enumerate(Population_Child_Weights) :\n",
        "                  OLS_Optimized_Weight = self._OLSReg(i_Child)\n",
        "                  #print(OLS_Optimized_Weight,'i:\\n', i, Population_Child_Weights[i])\n",
        "                  Population_Child_Weights[i] = OLS_Optimized_Weight\n",
        "            \n",
        "            \n",
        "            #step3 Evaluation\n",
        "            Population_Child_score = []\n",
        "            for i_Child in Population_Child_Weights :\n",
        "                \"\"\"\n",
        "                可能可以平行計算\n",
        "                \"\"\"\n",
        "                Population_Child_score.append( self._score(i_Child) )\n",
        "                 \n",
        "            BestNIndex = self._best(Population_Child_score)\n",
        "            Population_Parents_Weights = Population_Child_Weights[BestNIndex,:]\n",
        "            Population_Parents_Sigma = Population_Child_Sigma[BestNIndex,:]\n",
        "            \n",
        "            #更新best\n",
        "            best_weight_This_Iter =  Population_Child_Weights[BestNIndex,:][0]\n",
        "            best_score_This_Iter = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
        "            if best_score_This_Iter > self.best_score:\n",
        "                self.best_weight =  Population_Child_Weights[BestNIndex,:][0]\n",
        "                self.best_score = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
        "        \n",
        "            #print process \n",
        "            if ((self.cur_steps ) % verbose == 0) and verbose:\n",
        "               print(self)\n",
        "                \n",
        "            self.cur_steps = self.cur_steps + 1\n",
        "            #step4 check stop criteria\n",
        "            if self.cur_steps > max_steps:\n",
        "                print( 'Stop: Reach max_steps' )\n",
        "                break\n",
        "        return self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = self.best_weight), self.best_score \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NkGYn2e523KP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UR8bAYdozEEv"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ]
    },
    {
      "metadata": {
        "id": "dqQvjI11U0zb",
        "colab_type": "code",
        "outputId": "7b7a614c-0a63-4a1e-ff8e-1c1169b5dc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "#資料集是以dictionary的形式存在\n",
        "cancer = load_breast_cancer()\n",
        "df_feat = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
        "\n",
        "X = df_feat.iloc[:, ].values\n",
        "y = cancer['target']\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "y = labelencoder_X_1.fit_transform(y)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "#Feature Scaling\n",
        "\"\"\"from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\"\"\"\n",
        "\n",
        "#X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from sklearn.preprocessing import StandardScaler\\nsc = StandardScaler()\\nX_train = sc.fit_transform(X_train)\\nX_test = sc.transform(X_test)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LgjIusZlzDaT"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Compile"
      ]
    },
    {
      "metadata": {
        "id": "IBrIxe5CU5Nz",
        "colab_type": "code",
        "outputId": "14928888-e0d9-4fd6-ec41-68f80f096506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, Model as keras_models_Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(30,)))\n",
        "#model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(3, activation='relu', name = 'IntermediateLayer'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "IntermediateLayer (Dense)    (None, 3)                 33        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 347\n",
            "Trainable params: 347\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f5BM9m0lzRPv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# OLS Regression TEST"
      ]
    },
    {
      "metadata": {
        "id": "R3ExSfXBU61J",
        "colab_type": "code",
        "outputId": "7d979c2c-abc8-4395-ab4e-06db94f8c7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def _FlattenWeights(weights):\n",
        "    \"\"\"\n",
        "    flatten weights\n",
        "\n",
        "    param weights: keras神經網路的權重格式:nparray包在list中\n",
        "    return WeightsStrucure : 神經網路各層的權重shape包在list中，unflatten時會用到\n",
        "    return FlattenedWeights : 一維list包含所有的權重\n",
        "    \"\"\"\n",
        "    WeightsStrucure = []\n",
        "    FlattenedWeights = []\n",
        "    for i_layer in weights:\n",
        "        WeightsStrucure.append(i_layer.shape)\n",
        "        if len(i_layer.shape) == 1 :# 該層權重的shape為一維 e.g. (15,)      \n",
        "            FlattenedWeights.extend(i_layer)\n",
        "        else :# 該層權重的shape為二維 e.g. (30, 15)  \n",
        "            for i_links in i_layer:\n",
        "                FlattenedWeights.extend(i_links)\n",
        "    return WeightsStrucure, FlattenedWeights\n",
        "a,b=_FlattenWeights(weights)\n",
        "a[-2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "IyHeRtjbfp_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#weights[-2:] = weights[-2:]*0\n",
        "display(\n",
        "    'WeightsStrucure==========='\n",
        "    , WeightsStrucure\n",
        "    , 'WeightsStrucure[-2:]==========='\n",
        "    , WeightsStrucure[-2:] #最後一層的weights 及 bias\n",
        "    , 'weights==========='\n",
        "    , weights\n",
        "    , 'weights[-2:]==========='\n",
        "    , weights[-2:]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NsZOKrqgjS-0",
        "colab_type": "code",
        "outputId": "0d861ce2-7317-4730-c47e-31736709d8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "#%% OLS Regression\n",
        "#obtain the output of an intermediate layer\n",
        "#https://keras.io/getting-started/faq/?fbclid=IwAR3Zv35V-vmEy85anudOrlxCExXYwyG6cRL1UR0AaLPU6sZEoBjsbX-8LXQ#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
        "layer_name = 'IntermediateLayer'\n",
        "intermediate_layer_model = keras_models_Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "intermediate_output = intermediate_layer_model.predict(X_train)\n",
        "\n",
        "\n",
        "#fit LM\n",
        "lm = LinearRegression().fit(intermediate_output, y_train)\n",
        "# 印出係數, 截距 print(lm.coef_, lm.intercept_)\n",
        "\n",
        "#score\n",
        "score = log_loss(y_pred = lm.predict(intermediate_output), y_true= y_train)\n",
        "\n",
        "\n",
        "\n",
        "OutLayerWeights = [np.array(lm.coef_).reshape((3,1)), np.array(lm.intercept_).reshape((1))]\n",
        "\n",
        "#update ES-optimized weights\n",
        "weights[-2:] = OutLayerWeights        \n",
        "\n",
        "model.set_weights(weights)\n",
        "test_on_batch = model.test_on_batch(X_train, y_train, sample_weight=None) # return ['loss', 'acc']\n",
        "\n",
        "print( 'score',score, 'test_on_batch[1]',test_on_batch[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score nan test_on_batch[1] 0.6505495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1817: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1817: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0-V1mlLBha5I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights[-2:] = OutLayerWeights\n",
        "display(\n",
        "    'WeightsStrucure==========='\n",
        "    , WeightsStrucure\n",
        "    , 'WeightsStrucure[-2:]==========='\n",
        "    , WeightsStrucure[-2:] #最後一層的weights 及 bias\n",
        "    , 'weights==========='\n",
        "    , weights\n",
        "    , 'weights[-2:]==========='\n",
        "    , weights[-2:]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULIddEh0zWGU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Main"
      ]
    },
    {
      "metadata": {
        "id": "zE_V_96FU9yy",
        "colab_type": "code",
        "outputId": "13503c1e-ff7a-4064-f97e-359f6a60818a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1884
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "weights = model.get_weights() \n",
        "MyES = ES(model, X_train, y_train, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5)   \n",
        "weights, ES_Optimized_ObjVal  = MyES.run(weights, useOLSReg =True, max_steps=3, verbose = 1)\n",
        "\n",
        "# Optimize\n",
        "GlobalBestAccuracy = 0\n",
        "NoImproveTimes = 0\n",
        "while True:\n",
        "  # Gradient-based Optimize\n",
        "  model.set_weights(weights)\n",
        "  model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
        "  weights = model.get_weights() \n",
        "\n",
        "  # ES\n",
        "  weights, ES_Optimized_ObjVal  = MyES.run(weights, max_steps=5, verbose = 1)\n",
        "  \n",
        "  # Stop Criteria\n",
        "  if ES_Optimized_ObjVal > GlobalBestAccuracy:\n",
        "    GlobalBestAccuracy = ES_Optimized_ObjVal\n",
        "    NoImproveTimes = 0\n",
        "  else: \n",
        "    NoImproveTimes = NoImproveTimes + 1\n",
        "    if NoImproveTimes == 5:\n",
        "      break\n",
        "      "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ES STEPS: 1 BEST SCORE: 0.9363 \n",
            "ES STEPS: 2 BEST SCORE: 0.9363 \n",
            "ES STEPS: 3 BEST SCORE: 0.9363 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 53us/step - loss: 5.4052 - acc: 0.6571\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 51us/step - loss: 5.7813 - acc: 0.6374\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 55us/step - loss: 5.7813 - acc: 0.6374\n",
            "ES STEPS: 1 BEST SCORE: 0.8967 \n",
            "ES STEPS: 2 BEST SCORE: 0.9187 \n",
            "ES STEPS: 3 BEST SCORE: 0.9231 \n",
            "ES STEPS: 4 BEST SCORE: 0.9231 \n",
            "ES STEPS: 5 BEST SCORE: 0.9231 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8703 - acc: 0.9231\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 57us/step - loss: 0.8701 - acc: 0.9231\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.8698 - acc: 0.9231\n",
            "ES STEPS: 1 BEST SCORE: 0.9275 \n",
            "ES STEPS: 2 BEST SCORE: 0.9275 \n",
            "ES STEPS: 3 BEST SCORE: 0.9275 \n",
            "ES STEPS: 4 BEST SCORE: 0.9275 \n",
            "ES STEPS: 5 BEST SCORE: 0.9275 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.7469 - acc: 0.9297\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8420 - acc: 0.9187\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 51us/step - loss: 0.8860 - acc: 0.9121\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 45us/step - loss: 0.8326 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8322 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 53us/step - loss: 0.8318 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 56us/step - loss: 0.8314 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8310 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8306 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.8302 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 74us/step - loss: 0.8298 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.8294 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8290 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8286 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 58us/step - loss: 0.8283 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n",
            "Epoch 1/3\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.8279 - acc: 0.9319\n",
            "Epoch 2/3\n",
            "455/455 [==============================] - 0s 63us/step - loss: 0.8275 - acc: 0.9319\n",
            "Epoch 3/3\n",
            "455/455 [==============================] - 0s 60us/step - loss: 0.8272 - acc: 0.9319\n",
            "ES STEPS: 1 BEST SCORE: 0.9319 \n",
            "ES STEPS: 2 BEST SCORE: 0.9319 \n",
            "ES STEPS: 3 BEST SCORE: 0.9319 \n",
            "ES STEPS: 4 BEST SCORE: 0.9319 \n",
            "ES STEPS: 5 BEST SCORE: 0.9319 \n",
            "Stop: Reach max_steps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nw5YLWt3RtB6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}