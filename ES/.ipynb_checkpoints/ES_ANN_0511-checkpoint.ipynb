{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JlwH6ajIzAuM"
   },
   "source": [
    "# Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "du8JiNhSoMMQ"
   },
   "outputs": [],
   "source": [
    "#待續\n",
    "# 紅白酒資料>Ｙ分成01>split>score（recall, precision, AUC）\n",
    "# 親代個數先設定權重數目的2倍\n",
    "# 若無改善，試試看multi phase ES 迭代結果子代的10%再從頭開始\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rhYgessUEZb"
   },
   "outputs": [],
   "source": [
    "#https://github.com/YuTaNCCU/201902_ANN_Metaheuristic/tree/master/ES\n",
    "import random\n",
    "import pandas as pd\n",
    "from string import ascii_lowercase\n",
    "from copy import deepcopy\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from copy import deepcopy\n",
    "from collections import deque\n",
    "from numpy import argmax\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import  seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UR8bAYdozEEv"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNbHjxYPh0i5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4898, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6497, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>WineCatg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality WineCatg  \n",
       "0      9.4        5      red  \n",
       "1      9.8        5      red  \n",
       "2      9.8        5      red  \n",
       "3      9.8        6      red  \n",
       "4      9.4        5      red  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>WineCatg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality WineCatg  \n",
       "4893     11.2        6    white  \n",
       "4894      9.6        5    white  \n",
       "4895      9.4        6    white  \n",
       "4896     12.8        7    white  \n",
       "4897     11.8        6    white  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/YuTaNCCU/201902_ANN_Metaheuristic/master/Data/red.csv'\n",
    "red = pd.read_csv(url)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/YuTaNCCU/201902_ANN_Metaheuristic/master/Data/white.csv'\n",
    "white = pd.read_csv(url)\n",
    "\n",
    "red['WineCatg']='red'\n",
    "white['WineCatg']='white'\n",
    "Wine_Data = pd.concat([red, white])\n",
    "\n",
    "display(\n",
    "    red.shape,\n",
    "  white.shape,\n",
    "  Wine_Data.shape,\n",
    "  Wine_Data.head(5),\n",
    "  Wine_Data.tail(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原本各種quality記數: \n",
      " 3      30\n",
      "4     216\n",
      "5    2138\n",
      "6    2836\n",
      "7    1079\n",
      "8     193\n",
      "9       5\n",
      "Name: quality, dtype: int64\n",
      "分類成好壞兩種quality記數: \n",
      " 0    2384\n",
      "1    4113\n",
      "Name: quality, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>WineCatg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality WineCatg  \n",
       "0      9.4        0      red  \n",
       "1      9.8        0      red  \n",
       "2      9.8        0      red  \n",
       "3      9.8        1      red  \n",
       "4      9.4        0      red  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( '原本各種quality記數: \\n', Wine_Data.quality.value_counts().sort_index() )\n",
    "Wine_Data_Y01 = Wine_Data.replace({'quality':[3,4,5,6,7,8,9]},{'quality':[0,0,0,1,1,1,1]})\n",
    "print( '分類成好壞兩種quality記數: \\n', Wine_Data_Y01.quality.value_counts().sort_index() )\n",
    "Wine_Data_Y01.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4157, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1040, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1300, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4157,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1300,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=Wine_Data_Y01.drop(['quality', 'WineCatg'], axis=1)\n",
    "y=Wine_Data_Y01['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state= 123)\n",
    "\n",
    "display(\n",
    "      X_train.shape,\n",
    "      X_val.shape,\n",
    "      X_test.shape,\n",
    "      y_train.shape,\n",
    "      y_val.shape,\n",
    "      y_test.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isg-ogGRUHat"
   },
   "source": [
    "# Define ES class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "Eu47m1CnUrM1"
   },
   "outputs": [],
   "source": [
    "class ES:\n",
    "    \"\"\"\n",
    "    Conducts tabu search\n",
    "    \"\"\"\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    #default hyper parameters\n",
    "    InitialSigma = None\n",
    "    ParentsSize = None\n",
    "    ChildSize = None\n",
    "    tao = None\n",
    "    \n",
    "    #for input/output\n",
    "    KerasModels = None\n",
    "    WeightsStrucure = None   \n",
    "    weights = None\n",
    "    \n",
    "    #for record\n",
    "    cur_steps = 1\n",
    "    best_weight = None\n",
    "    best_score = None\n",
    "    \n",
    "    UseOLSReg=None\n",
    "    X_train=None\n",
    "    y_train=None\n",
    "    \n",
    "    def __init__(self, KerasModels, X_train, y_train, UseOLSReg=False, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5):\n",
    "        \"\"\"\n",
    "        :param KerasModels: a Keras model, like keras.engine.sequential.Sequential\n",
    "        :param weights: initial weights, should be a Keras model weight\n",
    "        :param max_steps: maximum number of steps to run algorithm for\n",
    "        :param UseOLSReg: If True, than use \"OLS Regression\" for the last layer\n",
    "        \n",
    "        \"\"\"\n",
    "        self.KerasModels = KerasModels\n",
    "        \n",
    "        self.UseOLSReg = UseOLSReg\n",
    "        \n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    " \n",
    "        if all(isinstance(x, float) for x in [InitialSigma, tao]) and all(x > 0 for x in [InitialSigma, tao]):\n",
    "            self.InitialSigma = InitialSigma\n",
    "            self.tao = tao\n",
    "        else:\n",
    "            raise TypeError('InitialSigma & tao must be a positive float')\n",
    "            \n",
    "        if all(isinstance(x, int) for x in [ParentsSize, ChildSize]) and all(x > 0 for x in [ParentsSize, ChildSize]):\n",
    "            self.ParentsSize = ParentsSize\n",
    "            self.ChildSize = ChildSize\n",
    "        else:\n",
    "            raise TypeError('ParentsSize, ChildSize & max_steps must be a positive integer')\n",
    "\n",
    "    def __str__(self): \n",
    "        return ('ES STEPS: %d ' +\n",
    "                'BEST SCORE: %.4f ') % \\\n",
    "               (self.cur_steps, self.best_score)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__() \n",
    "    \n",
    "    def _FlattenWeights(self, weights):\n",
    "        \"\"\"\n",
    "        flatten weights\n",
    "        \n",
    "        param weights: keras神經網路的權重格式:nparray包在list中\n",
    "        return WeightsStrucure : 神經網路各層的權重shape包在list中，unflatten時會用到\n",
    "        return FlattenedWeights : 一維list包含所有的權重\n",
    "        \"\"\"\n",
    "        WeightsStrucure = []\n",
    "        FlattenedWeights = []\n",
    "        for i_layer in weights:\n",
    "            WeightsStrucure.append(i_layer.shape)\n",
    "            if len(i_layer.shape) == 1 :# 該層權重的shape為一維 e.g. (15,)      \n",
    "                FlattenedWeights.extend(i_layer)\n",
    "            else :# 該層權重的shape為二維 e.g. (30, 15)  \n",
    "                for i_links in i_layer:\n",
    "                    FlattenedWeights.extend(i_links)\n",
    "        return WeightsStrucure, FlattenedWeights\n",
    "\n",
    "    def _UnflattenWeights(self, WeightsStrucure, ModifiedWeights):\n",
    "        \"\"\"\n",
    "        Unflatten(回復成原本的結構) weights  \n",
    "        \n",
    "        param WeightsStrucure : 神經網路各層的權重shape包在list中\n",
    "        param ModifiedWeights : 一維list包含所有meteHeuristic修改過的權重\n",
    "        return: keras神經網路的權重格式:nparray包在list中\n",
    "        \"\"\"\n",
    "        UnflattenWeights = []\n",
    "        i_index = 0 \n",
    "        for i_layer in WeightsStrucure:\n",
    "            if len(i_layer) == 1 : # 該層權重的shape為一維 e.g. (15,)      \n",
    "                TempList = ModifiedWeights[i_index:(i_index + i_layer[0])]\n",
    "                TempList = np.asarray(TempList)\n",
    "                i_index = i_index + i_layer[0]\n",
    "            else : # 該層權重的shape為二維 e.g. (30, 15)  \n",
    "                TempList = ModifiedWeights[i_index:(i_index + (i_layer[0]*i_layer[1]))]\n",
    "                TempList = np.reshape(TempList, i_layer )\n",
    "                i_index = i_index + (i_layer[0]*i_layer[1])\n",
    "            UnflattenWeights.append(TempList)\n",
    "        return UnflattenWeights   \n",
    "    \n",
    "    def _best(self, Population_Child_score):\n",
    "        \"\"\"\n",
    "        Finds the best member of a neighborhood\n",
    "        :param Population_Child_score: a np array\n",
    "        :return: the indtex of N best member, N = ParentsSize\n",
    "        \"\"\"\n",
    "        return np.array( Population_Child_score ).argsort()[::-1][:self.ParentsSize]\n",
    "    \n",
    "    def _Recombination(self, Population_Parents_Weights, Population_Parents_Sigma, rows): #GenerateParents\n",
    "        \"\"\"\n",
    "        Generate New Parents Polulation\n",
    "        \"\"\"\n",
    "        Population_Weights_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
    "        Population_Sigma_Recombination = np.zeros(shape = (rows, Population_Parents_Weights.shape[1]))\n",
    "        for index_row, _ in enumerate( Population_Weights_Recombination ):\n",
    "            \"\"\"\n",
    "            可能可以平行計算\n",
    "            \"\"\"\n",
    "            TwoRowschoiced = np.random.choice(Population_Parents_Weights.shape[0], size=2, replace=False,)\n",
    "            Parent1Mask = np.random.randint(2, size=Population_Parents_Weights.shape[1])\n",
    "            Parent2Mask = np.full(shape = Population_Parents_Weights.shape[1], fill_value = 1 )  - Parent1Mask\n",
    "            \n",
    "            Population_Weights_Recombination[index_row,:] = (Population_Parents_Weights[TwoRowschoiced] * [Parent1Mask, Parent2Mask]).sum(axis=0)\n",
    "            Population_Sigma_Recombination[index_row,:] = Population_Parents_Sigma[TwoRowschoiced].mean(axis=0)\n",
    "        return Population_Weights_Recombination, Population_Sigma_Recombination\n",
    "\n",
    "    def _score(self, ModifiedWeights):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns objective function value of a state\n",
    "\n",
    "        :param state: a state\n",
    "        :return: objective function value of state\n",
    "        \"\"\"\n",
    "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
    "        self.KerasModels.set_weights(UnflattenedWeights)\n",
    "        test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
    "        return test_on_batch[1]\n",
    "    #==================\n",
    "        #==================\n",
    "          #==================\n",
    "            #==================\n",
    "    def _OLSReg(self, ModifiedWeights):\n",
    "        \n",
    "        \"\"\"\n",
    "        :param : \n",
    "        :return: Keras Models, objective function value of state\n",
    "        \"\"\"\n",
    "        UnflattenedWeights = self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = ModifiedWeights)\n",
    "        \n",
    "        #%% OLS Regression\n",
    "        #obtain the output of an intermediate layer\n",
    "        #https://keras.io/getting-started/faq/?fbclid=IwAR3Zv35V-vmEy85anudOrlxCExXYwyG6cRL1UR0AaLPU6sZEoBjsbX-8LXQ#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "        self.KerasModels.set_weights(UnflattenedWeights)\n",
    "        layer_name = 'IntermediateLayer'\n",
    "        intermediate_layer_model = keras_models_Model(inputs=self.KerasModels.input,\n",
    "                                         outputs=self.KerasModels.get_layer(layer_name).output)\n",
    "        intermediate_output = intermediate_layer_model.predict(self.X_train)\n",
    "\n",
    "        #fit LM\n",
    "        lm =  LogisticRegression(random_state=0, solver='liblinear').fit(intermediate_output, self.y_train)\n",
    "        \n",
    "        #lm =  LinearRegression().fit(intermediate_output, self.y_train)\n",
    "        # 印出係數, 截距 print(lm.coef_, lm.intercept_)\n",
    "        \n",
    "        #score\n",
    "        #score = log_loss(y_pred = lm.predict(intermediate_output), y_true= self.y_train)\n",
    "        \n",
    "        #get OutLayerWeights\n",
    "        OutLayerWeights = [np.array(lm.coef_).reshape(self.WeightsStrucure[-2]),\n",
    "                           np.array(lm.intercept_).reshape(self.WeightsStrucure[-1])]\n",
    "\n",
    "        #update ES-optimized weights\n",
    "        UnflattenedWeights[-2:] = OutLayerWeights        \n",
    "        \n",
    "        #self.KerasModels.set_weights(UnflattenedWeights)\n",
    "        #test_on_batch = self.KerasModels.test_on_batch(self.X_train, self.y_train, sample_weight=None) # return ['loss', 'acc']\n",
    "        \n",
    "        #print( 'score',score, 'test_on_batch',test_on_batch)\n",
    "        _, OLS_Optimized_Weight = self._FlattenWeights(UnflattenedWeights)\n",
    "        return OLS_Optimized_Weight \n",
    "\n",
    "    def run(self, weights, max_steps=5, verbose=10, useOLSReg = False):\n",
    "        \"\"\"\n",
    "        Conducts ES\n",
    "        :param weights: \n",
    "        :param max_steps: \n",
    "        :param verbose: int which indicates how many iter to show score\n",
    "        :return: Keras Models, best state and objective function value of best state\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(weights, list)  :\n",
    "          \n",
    "            self.WeightsStrucure, self.weights = self._FlattenWeights(weights)\n",
    "            self.best_weight = self.weights\n",
    "            self.best_score = self._score(self.best_weight)\n",
    "        else:\n",
    "            raise TypeError('initial_state must be a list') \n",
    "            \n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "        #Step1 initial             \n",
    "        Population_Parents_Weights = np.array([self.weights, self.weights])         \n",
    "        Population_Parents_Sigma = np.full(shape = (self.ParentsSize, len(self.weights)), fill_value = self.InitialSigma ) \n",
    "        Population_Parents_Weights, _ = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ParentsSize )\n",
    "        self.cur_steps = 1\n",
    "        while True:   \n",
    "            #Step2 Child\n",
    "            ##Discrete Recombination\n",
    "            Population_Child_Weights, Population_Child_Sigma = self._Recombination(Population_Parents_Weights, Population_Parents_Sigma, rows = self.ChildSize )\n",
    "            ##mutation1\n",
    "            RamdonNormalValue = np.random.normal(0, 1, 1)\n",
    "            RamdonNormalValueDifferent = np.random.normal(0, 1, Population_Child_Sigma.shape)\n",
    "            Population_Child_Sigma = np.exp( (1-self.tao)*RamdonNormalValue + self.tao*RamdonNormalValueDifferent )\n",
    "            ##mutation2\n",
    "            Population_Child_Weights = Population_Child_Weights + np.random.normal(0, Population_Child_Sigma, Population_Child_Sigma.shape)\n",
    "            \n",
    "            \n",
    "            # OLS Regression\n",
    "            if useOLSReg == True:\n",
    "              for i, i_Child in enumerate(Population_Child_Weights) :\n",
    "                  OLS_Optimized_Weight = self._OLSReg(i_Child)\n",
    "                  #print(OLS_Optimized_Weight,'i:\\n', i, Population_Child_Weights[i])\n",
    "                  Population_Child_Weights[i] = OLS_Optimized_Weight\n",
    "            \n",
    "            \n",
    "            #step3 Evaluation\n",
    "            Population_Child_score = []\n",
    "            for i_Child in Population_Child_Weights :\n",
    "                \"\"\"\n",
    "                可能可以平行計算\n",
    "                \"\"\"\n",
    "                Population_Child_score.append( self._score(i_Child) )\n",
    "                 \n",
    "            BestNIndex = self._best(Population_Child_score)\n",
    "            Population_Parents_Weights = Population_Child_Weights[BestNIndex,:]\n",
    "            Population_Parents_Sigma = Population_Child_Sigma[BestNIndex,:]\n",
    "            \n",
    "            #更新best\n",
    "            best_weight_This_Iter =  Population_Child_Weights[BestNIndex,:][0]\n",
    "            best_score_This_Iter = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
    "            if best_score_This_Iter > self.best_score:\n",
    "                self.best_weight =  Population_Child_Weights[BestNIndex,:][0]\n",
    "                self.best_score = self._score(Population_Child_Weights[BestNIndex,:][0])\n",
    "        \n",
    "            #print process \n",
    "            if ((self.cur_steps ) % verbose == 0) and verbose:\n",
    "               print(self)\n",
    "                \n",
    "            self.cur_steps = self.cur_steps + 1\n",
    "            #step4 check stop criteria\n",
    "            if self.cur_steps > max_steps:\n",
    "                print( 'Stop: Reach max_steps' )\n",
    "                break\n",
    "        return self._UnflattenWeights(WeightsStrucure = self.WeightsStrucure, ModifiedWeights = self.best_weight), self.best_score \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgjIusZlzDaT"
   },
   "source": [
    "# Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "IBrIxe5CU5Nz",
    "outputId": "14928888-e0d9-4fd6-ec41-68f80f096506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "IntermediateLayer (Dense)    (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, Model as keras_models_Model\n",
    "\n",
    "K.clear_session() \n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(round(X_train.shape[1]/2), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "#model.add(Dense(round(X_train.shape[1]/2), activation='relu'))\n",
    "model.add(Dense(round(X_train.shape[1]/4), activation='relu', name = 'IntermediateLayer'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULIddEh0zWGU"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1884
    },
    "colab_type": "code",
    "id": "zE_V_96FU9yy",
    "outputId": "13503c1e-ff7a-4064-f97e-359f6a60818a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES STEPS: 1 BEST SCORE: 0.6618 \n",
      "ES STEPS: 2 BEST SCORE: 0.6690 \n",
      "ES STEPS: 3 BEST SCORE: 0.6690 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2878 - acc: 0.6688\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.3581 - acc: 0.6647\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 73us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 72us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2747 - acc: 0.6700\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2747 - acc: 0.6700\n",
      "ES STEPS: 1 BEST SCORE: 0.6724 \n",
      "ES STEPS: 2 BEST SCORE: 0.6738 \n",
      "ES STEPS: 3 BEST SCORE: 0.6738 \n",
      "ES STEPS: 4 BEST SCORE: 0.6738 \n",
      "ES STEPS: 5 BEST SCORE: 0.6738 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1983 - acc: 0.6745\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2172 - acc: 0.6738\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2172 - acc: 0.6738\n",
      "ES STEPS: 1 BEST SCORE: 0.6738 \n",
      "ES STEPS: 2 BEST SCORE: 0.6738 \n",
      "ES STEPS: 3 BEST SCORE: 0.6738 \n",
      "ES STEPS: 4 BEST SCORE: 0.6738 \n",
      "ES STEPS: 5 BEST SCORE: 0.6777 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1914 - acc: 0.6748\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.4210 - acc: 0.6611\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.4106 - acc: 0.6615\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.3089 - acc: 0.6678\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.6989 - acc: 0.6442\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.6600 - acc: 0.6464\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.6418 - acc: 0.6478\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.6418 - acc: 0.6478\n",
      "ES STEPS: 1 BEST SCORE: 0.6781 \n",
      "ES STEPS: 2 BEST SCORE: 0.6781 \n",
      "ES STEPS: 3 BEST SCORE: 0.6781 \n",
      "ES STEPS: 4 BEST SCORE: 0.6781 \n",
      "ES STEPS: 5 BEST SCORE: 0.6781 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2019 - acc: 0.6743\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1844 - acc: 0.6752\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2344 - acc: 0.6726\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 71us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.2674 - acc: 0.6707\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 71us/step - loss: 5.2674 - acc: 0.6707\n",
      "ES STEPS: 1 BEST SCORE: 0.6791 \n",
      "ES STEPS: 2 BEST SCORE: 0.6801 \n",
      "ES STEPS: 3 BEST SCORE: 0.6813 \n",
      "ES STEPS: 4 BEST SCORE: 0.6813 \n",
      "ES STEPS: 5 BEST SCORE: 0.6813 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0921 - acc: 0.6813\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0992 - acc: 0.6803\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1266 - acc: 0.6791\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1383 - acc: 0.6781\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1404 - acc: 0.6779\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1251 - acc: 0.6791\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1270 - acc: 0.6784\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1206 - acc: 0.6789\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1373 - acc: 0.6781\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1917 - acc: 0.6748\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1917 - acc: 0.6748\n",
      "ES STEPS: 1 BEST SCORE: 0.6786 \n",
      "ES STEPS: 2 BEST SCORE: 0.6786 \n",
      "ES STEPS: 3 BEST SCORE: 0.6786 \n",
      "ES STEPS: 4 BEST SCORE: 0.6786 \n",
      "ES STEPS: 5 BEST SCORE: 0.6786 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.1252 - acc: 0.6791\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1190 - acc: 0.6793\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.2067 - acc: 0.6740\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2294 - acc: 0.6724\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1775 - acc: 0.6760\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.2767 - acc: 0.6700\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2768 - acc: 0.6700\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.2768 - acc: 0.6700\n",
      "ES STEPS: 1 BEST SCORE: 0.6798 \n",
      "ES STEPS: 2 BEST SCORE: 0.6798 \n",
      "ES STEPS: 3 BEST SCORE: 0.6798 \n",
      "ES STEPS: 4 BEST SCORE: 0.6798 \n",
      "ES STEPS: 5 BEST SCORE: 0.6798 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 70us/step - loss: 5.1559 - acc: 0.6769\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.1873 - acc: 0.6748\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1161 - acc: 0.6796\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.1412 - acc: 0.6779\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 70us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.1759 - acc: 0.6757\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.1759 - acc: 0.6757\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 66us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 71us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 73us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 67us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 69us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 68us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n",
      "Epoch 1/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 2/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 3/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 4/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 5/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 6/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 7/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 8/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 9/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 10/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 11/15\n",
      "4157/4157 [==============================] - 0s 63us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 12/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 13/15\n",
      "4157/4157 [==============================] - 0s 65us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 14/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "Epoch 15/15\n",
      "4157/4157 [==============================] - 0s 64us/step - loss: 5.0771 - acc: 0.6820\n",
      "ES STEPS: 1 BEST SCORE: 0.6820 \n",
      "ES STEPS: 2 BEST SCORE: 0.6820 \n",
      "ES STEPS: 3 BEST SCORE: 0.6820 \n",
      "ES STEPS: 4 BEST SCORE: 0.6820 \n",
      "ES STEPS: 5 BEST SCORE: 0.6820 \n",
      "Stop: Reach max_steps\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "weights = model.get_weights() \n",
    "MyES = ES(model, X_train, y_train, InitialSigma = 0.1, ParentsSize = 15, ChildSize = 100, tao = 0.5)   \n",
    "weights, ES_Optimized_ObjVal  = MyES.run(weights, useOLSReg =False, max_steps=3, verbose = 1)\n",
    "\n",
    "# Optimize\n",
    "GlobalBestAccuracy = 0\n",
    "NoImproveTimes = 0\n",
    "while True:\n",
    "  # Gradient-based Optimize\n",
    "  model.set_weights(weights)\n",
    "  model.fit(X_train, y_train, epochs=15, batch_size=32, verbose=1)\n",
    "  weights = model.get_weights() \n",
    "\n",
    "  # ES\n",
    "  weights, ES_Optimized_ObjVal  = MyES.run(weights, max_steps=5, verbose = 1)\n",
    "  \n",
    "  # Stop Criteria\n",
    "  if ES_Optimized_ObjVal > GlobalBestAccuracy:\n",
    "    GlobalBestAccuracy = ES_Optimized_ObjVal\n",
    "    NoImproveTimes = 0\n",
    "  else: \n",
    "    NoImproveTimes = NoImproveTimes + 1\n",
    "    if NoImproveTimes == 5:\n",
    "      break\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 66.84615384615384%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_score = model.predict(X_test) #X_train X_test\n",
    "y_pred = (y_score > 0.5)  #y_pred 有 NA\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred) #y_train y_test\n",
    "\n",
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/sum(sum(cm)))*100))\n",
    "\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5834668803418803"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true=y_test, y_score=y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nw5YLWt3RtB6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ROC curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes =2\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_score)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "f5BM9m0lzRPv"
   ],
   "name": "ES_ANN_0508",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
